{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8848655,"sourceType":"datasetVersion","datasetId":5326116}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-05T03:46:03.447025Z","iopub.execute_input":"2024-07-05T03:46:03.448242Z","iopub.status.idle":"2024-07-05T03:46:03.453677Z","shell.execute_reply.started":"2024-07-05T03:46:03.448202Z","shell.execute_reply":"2024-07-05T03:46:03.452588Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport joblib\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:03.455432Z","iopub.execute_input":"2024-07-05T03:46:03.455806Z","iopub.status.idle":"2024-07-05T03:46:03.467649Z","shell.execute_reply.started":"2024-07-05T03:46:03.455774Z","shell.execute_reply":"2024-07-05T03:46:03.466802Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(r\"/kaggle/input/feature-common-language/audio_features_partial.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:03.468998Z","iopub.execute_input":"2024-07-05T03:46:03.469310Z","iopub.status.idle":"2024-07-05T03:46:04.176945Z","shell.execute_reply.started":"2024-07-05T03:46:03.469280Z","shell.execute_reply":"2024-07-05T03:46:04.175957Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n0     0.712224  0.055740        2989.050985         2193.800068   \n1     0.598403  0.074004        2372.315827         2065.561020   \n2     0.756316  0.046051        3274.178654         2196.474265   \n3     0.588983  0.061376        1948.418292         2049.242741   \n4     0.647222  0.069638        1705.618989         1824.714129   \n\n   spectral_rolloff  zero_crossing_rate     mfcc_1     mfcc_2     mfcc_3  \\\n0       5666.294643            0.275144 -202.32579  27.614292   4.094784   \n1       4795.649510            0.178041 -137.41476  59.931843   5.077963   \n2       5870.572917            0.353054 -233.02031  22.691550  10.057923   \n3       4186.921296            0.137682 -199.04490  80.806870  31.451380   \n4       3730.709877            0.095540 -325.47556  92.373820  17.725632   \n\n      mfcc_4  ...    mfcc_13   mfcc_14    mfcc_15   mfcc_16   mfcc_17  \\\n0   5.301181  ...   4.752774 -0.985637  -6.752584 -4.679379 -5.478848   \n1  -5.712012  ... -12.469353 -2.134825 -10.989368 -1.460541 -4.485021   \n2   3.829097  ...  -1.657243 -5.409642  -4.017134 -6.744406 -1.697630   \n3  -1.297673  ...  -4.202263  0.065943  -9.312079 -7.164060 -3.082040   \n4  31.867613  ...   3.169903  4.538502  -1.073114 -1.204524 -0.108214   \n\n    mfcc_18   mfcc_19   mfcc_20   label  \\\n0 -0.866508 -1.919669 -0.634521  Arabic   \n1 -0.408789 -8.211143 -5.170048  Arabic   \n2 -0.387302  0.829549  1.292110  Arabic   \n3 -8.046175 -3.083879 -2.018449  Arabic   \n4 -4.803460 -2.882802 -1.455632  Arabic   \n\n                                           file_path  \n0  /kaggle/input/preprocess-common-language/proce...  \n1  /kaggle/input/preprocess-common-language/proce...  \n2  /kaggle/input/preprocess-common-language/proce...  \n3  /kaggle/input/preprocess-common-language/proce...  \n4  /kaggle/input/preprocess-common-language/proce...  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chroma_stft</th>\n      <th>rms</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>spectral_rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc_1</th>\n      <th>mfcc_2</th>\n      <th>mfcc_3</th>\n      <th>mfcc_4</th>\n      <th>...</th>\n      <th>mfcc_13</th>\n      <th>mfcc_14</th>\n      <th>mfcc_15</th>\n      <th>mfcc_16</th>\n      <th>mfcc_17</th>\n      <th>mfcc_18</th>\n      <th>mfcc_19</th>\n      <th>mfcc_20</th>\n      <th>label</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.712224</td>\n      <td>0.055740</td>\n      <td>2989.050985</td>\n      <td>2193.800068</td>\n      <td>5666.294643</td>\n      <td>0.275144</td>\n      <td>-202.32579</td>\n      <td>27.614292</td>\n      <td>4.094784</td>\n      <td>5.301181</td>\n      <td>...</td>\n      <td>4.752774</td>\n      <td>-0.985637</td>\n      <td>-6.752584</td>\n      <td>-4.679379</td>\n      <td>-5.478848</td>\n      <td>-0.866508</td>\n      <td>-1.919669</td>\n      <td>-0.634521</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.598403</td>\n      <td>0.074004</td>\n      <td>2372.315827</td>\n      <td>2065.561020</td>\n      <td>4795.649510</td>\n      <td>0.178041</td>\n      <td>-137.41476</td>\n      <td>59.931843</td>\n      <td>5.077963</td>\n      <td>-5.712012</td>\n      <td>...</td>\n      <td>-12.469353</td>\n      <td>-2.134825</td>\n      <td>-10.989368</td>\n      <td>-1.460541</td>\n      <td>-4.485021</td>\n      <td>-0.408789</td>\n      <td>-8.211143</td>\n      <td>-5.170048</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.756316</td>\n      <td>0.046051</td>\n      <td>3274.178654</td>\n      <td>2196.474265</td>\n      <td>5870.572917</td>\n      <td>0.353054</td>\n      <td>-233.02031</td>\n      <td>22.691550</td>\n      <td>10.057923</td>\n      <td>3.829097</td>\n      <td>...</td>\n      <td>-1.657243</td>\n      <td>-5.409642</td>\n      <td>-4.017134</td>\n      <td>-6.744406</td>\n      <td>-1.697630</td>\n      <td>-0.387302</td>\n      <td>0.829549</td>\n      <td>1.292110</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.588983</td>\n      <td>0.061376</td>\n      <td>1948.418292</td>\n      <td>2049.242741</td>\n      <td>4186.921296</td>\n      <td>0.137682</td>\n      <td>-199.04490</td>\n      <td>80.806870</td>\n      <td>31.451380</td>\n      <td>-1.297673</td>\n      <td>...</td>\n      <td>-4.202263</td>\n      <td>0.065943</td>\n      <td>-9.312079</td>\n      <td>-7.164060</td>\n      <td>-3.082040</td>\n      <td>-8.046175</td>\n      <td>-3.083879</td>\n      <td>-2.018449</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.647222</td>\n      <td>0.069638</td>\n      <td>1705.618989</td>\n      <td>1824.714129</td>\n      <td>3730.709877</td>\n      <td>0.095540</td>\n      <td>-325.47556</td>\n      <td>92.373820</td>\n      <td>17.725632</td>\n      <td>31.867613</td>\n      <td>...</td>\n      <td>3.169903</td>\n      <td>4.538502</td>\n      <td>-1.073114</td>\n      <td>-1.204524</td>\n      <td>-0.108214</td>\n      <td>-4.803460</td>\n      <td>-2.882802</td>\n      <td>-1.455632</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:04.179725Z","iopub.execute_input":"2024-07-05T03:46:04.180127Z","iopub.status.idle":"2024-07-05T03:46:04.370568Z","shell.execute_reply.started":"2024-07-05T03:46:04.180091Z","shell.execute_reply":"2024-07-05T03:46:04.369731Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit LabelEncoder with your actual labels\nlabel_encoder.fit(df['label'])\n\n# Transform actual labels to numeric labels\ndf['numeric_labels'] = label_encoder.transform(df['label'])","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:04.372016Z","iopub.execute_input":"2024-07-05T03:46:04.372367Z","iopub.status.idle":"2024-07-05T03:46:04.400260Z","shell.execute_reply.started":"2024-07-05T03:46:04.372335Z","shell.execute_reply":"2024-07-05T03:46:04.399397Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['label','numeric_labels','file_path'])\ny = df['numeric_labels']","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:04.401275Z","iopub.execute_input":"2024-07-05T03:46:04.401590Z","iopub.status.idle":"2024-07-05T03:46:04.413315Z","shell.execute_reply.started":"2024-07-05T03:46:04.401556Z","shell.execute_reply":"2024-07-05T03:46:04.412593Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:04.414382Z","iopub.execute_input":"2024-07-05T03:46:04.414638Z","iopub.status.idle":"2024-07-05T03:46:05.317982Z","shell.execute_reply.started":"2024-07-05T03:46:04.414614Z","shell.execute_reply":"2024-07-05T03:46:05.316971Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\n# Jumlah kelas sebelum SMOTE\nprint(\"Jumlah kelas sebelum SMOTE:\")\nprint(Counter(y))\n\n# Jumlah kelas setelah SMOTE\nprint(\"\\nJumlah kelas setelah SMOTE:\")\nprint(Counter(y_resampled))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:05.319277Z","iopub.execute_input":"2024-07-05T03:46:05.319600Z","iopub.status.idle":"2024-07-05T03:46:05.370748Z","shell.execute_reply.started":"2024-07-05T03:46:05.319572Z","shell.execute_reply":"2024-07-05T03:46:05.369851Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Jumlah kelas sebelum SMOTE:\nCounter({2: 3570, 39: 3177, 19: 3012, 6: 3003, 27: 2955, 41: 2784, 24: 2766, 0: 2751, 20: 2733, 37: 2691, 10: 2550, 33: 2547, 18: 2520, 21: 2484, 42: 2472, 8: 2442, 40: 2367, 26: 2331, 30: 2283, 28: 2277, 23: 2268, 32: 2238, 7: 2202, 31: 2196, 43: 2181, 15: 2073, 44: 2073, 5: 2016, 34: 1977, 9: 1962, 25: 1947, 12: 1932, 1: 1914, 16: 1890, 29: 1884, 14: 1863, 3: 1830, 17: 1830, 4: 1797, 11: 1773, 35: 1758, 36: 1752, 38: 1737, 22: 1695, 13: 1623})\n\nJumlah kelas setelah SMOTE:\nCounter({0: 3570, 4: 3570, 9: 3570, 27: 3570, 18: 3570, 24: 3570, 23: 3570, 13: 3570, 20: 3570, 11: 3570, 16: 3570, 40: 3570, 28: 3570, 15: 3570, 21: 3570, 8: 3570, 31: 3570, 29: 3570, 5: 3570, 7: 3570, 41: 3570, 44: 3570, 3: 3570, 2: 3570, 14: 3570, 43: 3570, 36: 3570, 26: 3570, 34: 3570, 12: 3570, 37: 3570, 35: 3570, 42: 3570, 33: 3570, 17: 3570, 25: 3570, 6: 3570, 30: 3570, 39: 3570, 22: 3570, 10: 3570, 1: 3570, 19: 3570, 32: 3570, 38: 3570})\n","output_type":"stream"}]},{"cell_type":"code","source":"### split data 80% 20%\n\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,\n                                                    test_size=0.2, random_state=42,\n                                                    stratify=y_resampled)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:05.372080Z","iopub.execute_input":"2024-07-05T03:46:05.372731Z","iopub.status.idle":"2024-07-05T03:46:05.483176Z","shell.execute_reply.started":"2024-07-05T03:46:05.372703Z","shell.execute_reply":"2024-07-05T03:46:05.482049Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Inisialisasi StandardScaler\nscaler = StandardScaler()\n\n# Fit scaler pada data training dan transform kedua set data\nX_train_normalized = scaler.fit_transform(X_train)\nX_test_normalized = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:05.486765Z","iopub.execute_input":"2024-07-05T03:46:05.487149Z","iopub.status.idle":"2024-07-05T03:46:05.546257Z","shell.execute_reply.started":"2024-07-05T03:46:05.487120Z","shell.execute_reply":"2024-07-05T03:46:05.545125Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X_train_normalized)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:05.547490Z","iopub.execute_input":"2024-07-05T03:46:05.548065Z","iopub.status.idle":"2024-07-05T03:46:05.583896Z","shell.execute_reply.started":"2024-07-05T03:46:05.548028Z","shell.execute_reply":"2024-07-05T03:46:05.582994Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"              0         1         2         3         4         5         6   \\\n0      -0.125270 -0.462618 -0.063722  0.962710  0.546778 -0.530245 -0.215304   \n1      -0.447086 -0.164635 -0.081286  0.298297  0.031393 -0.255482  0.851859   \n2      -0.136721  0.693945 -0.652197  0.593003 -0.029296 -1.373536  0.804041   \n3      -1.041236  1.421366 -0.560796  0.131813 -0.337850 -0.264703  0.680879   \n4      -0.923043 -0.815273  0.428687  0.336918  0.459523  0.063171  0.295056   \n...          ...       ...       ...       ...       ...       ...       ...   \n128515 -1.069659  0.820296 -1.411504 -1.652472 -1.413538 -0.950462 -2.531171   \n128516  0.000360 -0.463296 -0.023205  0.176157 -0.034989 -0.226584  0.809894   \n128517 -2.370420  1.866536 -1.352947 -1.059491 -1.572022 -0.799900 -0.373726   \n128518  0.146890 -0.653630  0.677426  0.721152  0.754992  0.370645  0.048390   \n128519 -0.280134 -0.703109  0.021005  0.566020  0.206863 -0.449980 -0.051016   \n\n              7         8         9   ...        16        17        18  \\\n0      -0.176643  1.412404  0.383635  ...  0.193716  0.060471  0.656303   \n1      -0.201491 -0.137365  0.157049  ... -1.101902 -1.626334  0.223691   \n2       0.107182  0.606830  0.598271  ... -0.054259 -1.238785 -1.046840   \n3      -0.053193  0.069079  0.717965  ... -1.921328  0.441973  0.176668   \n4      -0.775594 -1.244932 -2.012682  ...  0.224048  0.497766  0.512246   \n...          ...       ...       ...  ...       ...       ...       ...   \n128515  1.026397 -0.282676  2.174811  ... -1.828143  0.285871  0.049287   \n128516 -0.064593 -0.741426 -1.760898  ...  0.442690  0.649209 -0.596835   \n128517  1.257349  0.578946  0.872449  ...  0.865331 -0.488842  0.075970   \n128518 -0.953738  0.222994  0.610338  ... -0.512452 -1.230825  0.102356   \n128519 -0.075521  0.300568 -0.216127  ... -0.123118 -0.241533  0.031778   \n\n              19        20        21        22        23        24        25  \n0      -0.022266  0.317852 -0.352507 -1.010202 -1.367641 -1.260068 -1.444051  \n1       0.817619 -1.296437 -0.614610 -0.134165 -3.339167 -0.671473  0.503199  \n2      -2.431179 -2.554992 -2.492506 -0.366025 -0.626432  0.076768  0.491064  \n3      -2.161943  0.177355  0.315965 -1.888467  0.640302  0.116856 -1.150069  \n4      -0.309098 -0.438342  0.097450  0.281906  0.694139  0.955619 -1.263811  \n...          ...       ...       ...       ...       ...       ...       ...  \n128515  0.720958  0.020781 -1.278091 -0.628007  0.212564 -1.642634 -2.222433  \n128516 -1.256466 -0.773914 -1.425531 -1.128419 -0.704997 -0.171163  0.474619  \n128517  0.050136 -1.373727  0.271099 -0.194054 -0.750243 -1.434839  0.372517  \n128518  0.297172 -0.461706 -1.169560 -0.183656  0.060295  0.011697  0.617881  \n128519  0.275208  1.477354  1.799078  2.096360  1.079606  0.597507  0.833435  \n\n[128520 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.125270</td>\n      <td>-0.462618</td>\n      <td>-0.063722</td>\n      <td>0.962710</td>\n      <td>0.546778</td>\n      <td>-0.530245</td>\n      <td>-0.215304</td>\n      <td>-0.176643</td>\n      <td>1.412404</td>\n      <td>0.383635</td>\n      <td>...</td>\n      <td>0.193716</td>\n      <td>0.060471</td>\n      <td>0.656303</td>\n      <td>-0.022266</td>\n      <td>0.317852</td>\n      <td>-0.352507</td>\n      <td>-1.010202</td>\n      <td>-1.367641</td>\n      <td>-1.260068</td>\n      <td>-1.444051</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.447086</td>\n      <td>-0.164635</td>\n      <td>-0.081286</td>\n      <td>0.298297</td>\n      <td>0.031393</td>\n      <td>-0.255482</td>\n      <td>0.851859</td>\n      <td>-0.201491</td>\n      <td>-0.137365</td>\n      <td>0.157049</td>\n      <td>...</td>\n      <td>-1.101902</td>\n      <td>-1.626334</td>\n      <td>0.223691</td>\n      <td>0.817619</td>\n      <td>-1.296437</td>\n      <td>-0.614610</td>\n      <td>-0.134165</td>\n      <td>-3.339167</td>\n      <td>-0.671473</td>\n      <td>0.503199</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.136721</td>\n      <td>0.693945</td>\n      <td>-0.652197</td>\n      <td>0.593003</td>\n      <td>-0.029296</td>\n      <td>-1.373536</td>\n      <td>0.804041</td>\n      <td>0.107182</td>\n      <td>0.606830</td>\n      <td>0.598271</td>\n      <td>...</td>\n      <td>-0.054259</td>\n      <td>-1.238785</td>\n      <td>-1.046840</td>\n      <td>-2.431179</td>\n      <td>-2.554992</td>\n      <td>-2.492506</td>\n      <td>-0.366025</td>\n      <td>-0.626432</td>\n      <td>0.076768</td>\n      <td>0.491064</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.041236</td>\n      <td>1.421366</td>\n      <td>-0.560796</td>\n      <td>0.131813</td>\n      <td>-0.337850</td>\n      <td>-0.264703</td>\n      <td>0.680879</td>\n      <td>-0.053193</td>\n      <td>0.069079</td>\n      <td>0.717965</td>\n      <td>...</td>\n      <td>-1.921328</td>\n      <td>0.441973</td>\n      <td>0.176668</td>\n      <td>-2.161943</td>\n      <td>0.177355</td>\n      <td>0.315965</td>\n      <td>-1.888467</td>\n      <td>0.640302</td>\n      <td>0.116856</td>\n      <td>-1.150069</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.923043</td>\n      <td>-0.815273</td>\n      <td>0.428687</td>\n      <td>0.336918</td>\n      <td>0.459523</td>\n      <td>0.063171</td>\n      <td>0.295056</td>\n      <td>-0.775594</td>\n      <td>-1.244932</td>\n      <td>-2.012682</td>\n      <td>...</td>\n      <td>0.224048</td>\n      <td>0.497766</td>\n      <td>0.512246</td>\n      <td>-0.309098</td>\n      <td>-0.438342</td>\n      <td>0.097450</td>\n      <td>0.281906</td>\n      <td>0.694139</td>\n      <td>0.955619</td>\n      <td>-1.263811</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>128515</th>\n      <td>-1.069659</td>\n      <td>0.820296</td>\n      <td>-1.411504</td>\n      <td>-1.652472</td>\n      <td>-1.413538</td>\n      <td>-0.950462</td>\n      <td>-2.531171</td>\n      <td>1.026397</td>\n      <td>-0.282676</td>\n      <td>2.174811</td>\n      <td>...</td>\n      <td>-1.828143</td>\n      <td>0.285871</td>\n      <td>0.049287</td>\n      <td>0.720958</td>\n      <td>0.020781</td>\n      <td>-1.278091</td>\n      <td>-0.628007</td>\n      <td>0.212564</td>\n      <td>-1.642634</td>\n      <td>-2.222433</td>\n    </tr>\n    <tr>\n      <th>128516</th>\n      <td>0.000360</td>\n      <td>-0.463296</td>\n      <td>-0.023205</td>\n      <td>0.176157</td>\n      <td>-0.034989</td>\n      <td>-0.226584</td>\n      <td>0.809894</td>\n      <td>-0.064593</td>\n      <td>-0.741426</td>\n      <td>-1.760898</td>\n      <td>...</td>\n      <td>0.442690</td>\n      <td>0.649209</td>\n      <td>-0.596835</td>\n      <td>-1.256466</td>\n      <td>-0.773914</td>\n      <td>-1.425531</td>\n      <td>-1.128419</td>\n      <td>-0.704997</td>\n      <td>-0.171163</td>\n      <td>0.474619</td>\n    </tr>\n    <tr>\n      <th>128517</th>\n      <td>-2.370420</td>\n      <td>1.866536</td>\n      <td>-1.352947</td>\n      <td>-1.059491</td>\n      <td>-1.572022</td>\n      <td>-0.799900</td>\n      <td>-0.373726</td>\n      <td>1.257349</td>\n      <td>0.578946</td>\n      <td>0.872449</td>\n      <td>...</td>\n      <td>0.865331</td>\n      <td>-0.488842</td>\n      <td>0.075970</td>\n      <td>0.050136</td>\n      <td>-1.373727</td>\n      <td>0.271099</td>\n      <td>-0.194054</td>\n      <td>-0.750243</td>\n      <td>-1.434839</td>\n      <td>0.372517</td>\n    </tr>\n    <tr>\n      <th>128518</th>\n      <td>0.146890</td>\n      <td>-0.653630</td>\n      <td>0.677426</td>\n      <td>0.721152</td>\n      <td>0.754992</td>\n      <td>0.370645</td>\n      <td>0.048390</td>\n      <td>-0.953738</td>\n      <td>0.222994</td>\n      <td>0.610338</td>\n      <td>...</td>\n      <td>-0.512452</td>\n      <td>-1.230825</td>\n      <td>0.102356</td>\n      <td>0.297172</td>\n      <td>-0.461706</td>\n      <td>-1.169560</td>\n      <td>-0.183656</td>\n      <td>0.060295</td>\n      <td>0.011697</td>\n      <td>0.617881</td>\n    </tr>\n    <tr>\n      <th>128519</th>\n      <td>-0.280134</td>\n      <td>-0.703109</td>\n      <td>0.021005</td>\n      <td>0.566020</td>\n      <td>0.206863</td>\n      <td>-0.449980</td>\n      <td>-0.051016</td>\n      <td>-0.075521</td>\n      <td>0.300568</td>\n      <td>-0.216127</td>\n      <td>...</td>\n      <td>-0.123118</td>\n      <td>-0.241533</td>\n      <td>0.031778</td>\n      <td>0.275208</td>\n      <td>1.477354</td>\n      <td>1.799078</td>\n      <td>2.096360</td>\n      <td>1.079606</td>\n      <td>0.597507</td>\n      <td>0.833435</td>\n    </tr>\n  </tbody>\n</table>\n<p>128520 rows Ã— 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:05.585146Z","iopub.execute_input":"2024-07-05T03:46:05.585492Z","iopub.status.idle":"2024-07-05T03:46:05.590618Z","shell.execute_reply.started":"2024-07-05T03:46:05.585459Z","shell.execute_reply":"2024-07-05T03:46:05.589720Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport pandas as pd\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:05.592090Z","iopub.execute_input":"2024-07-05T03:46:05.592774Z","iopub.status.idle":"2024-07-05T03:46:05.604976Z","shell.execute_reply.started":"2024-07-05T03:46:05.592746Z","shell.execute_reply":"2024-07-05T03:46:05.604092Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Inisialisasi KNN\nknn = KNeighborsClassifier(n_neighbors=1)\n\n# Parameter grid\nparam_grid = {\n    'weights': ['uniform', 'distance'],\n    'metric': ['euclidean', 'manhattan', 'minkowski'],\n    'p': [1, 2],  # Hanya relevan untuk metrik Minkowski\n    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n}\n\n# Buat GridSearchCV tanpa custom scorer\ngrid_search = GridSearchCV(\n    knn, \n    param_grid, \n    cv=3, \n    n_jobs=1,  # Run sequentially\n    verbose=1  # This will show progress\n)\n\n\n# Fit RandomizedSearchCV\ngrid_search.fit(X_train, y_train)\n\n# Tampilkan parameter terbaik\nprint(\"Parameter terbaik:\", grid_search.best_params_)\nprint(\"Skor terbaik:\", grid_search.best_score_)\n\n# Buat DataFrame dari hasil\nresults = pd.DataFrame(grid_search.cv_results_)\n\n# Urutkan berdasarkan mean test score dari yang tertinggi ke terendah\nresults = results.sort_values('mean_test_score', ascending=False)\n\n# Tampilkan kolom yang relevan\ncolumns_to_display = ['params', 'mean_test_score', 'std_test_score', 'rank_test_score']\nprint(results[columns_to_display].to_string(index=False))\n\n# Gunakan model terbaik untuk prediksi\nbest_knn = grid_search.best_estimator_\ny_pred = best_knn.predict(X_test)\n\n# Evaluasi model terbaik\nprint(\"Akurasi model terbaik:\", accuracy_score(y_test, y_pred))\nprint(\"\\nLaporan Klasifikasi:\")\nprint(classification_report(y_test, y_pred))\n\n# Simpan hasil ke CSV jika diperlukan\nresults[columns_to_display].to_csv('grid_search_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T03:46:11.590604Z","iopub.execute_input":"2024-07-05T03:46:11.590954Z","iopub.status.idle":"2024-07-05T04:38:09.968650Z","shell.execute_reply.started":"2024-07-05T03:46:11.590928Z","shell.execute_reply":"2024-07-05T04:38:09.967679Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 48 candidates, totalling 144 fits\nParameter terbaik: {'algorithm': 'auto', 'metric': 'manhattan', 'p': 1, 'weights': 'uniform'}\nSkor terbaik: 0.6061235605353251\n                                                                          params  mean_test_score  std_test_score  rank_test_score\n     {'algorithm': 'auto', 'metric': 'manhattan', 'p': 2, 'weights': 'distance'}         0.606124        0.000058                1\n      {'algorithm': 'auto', 'metric': 'manhattan', 'p': 2, 'weights': 'uniform'}         0.606124        0.000058                1\n     {'algorithm': 'auto', 'metric': 'manhattan', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n      {'algorithm': 'auto', 'metric': 'manhattan', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n     {'algorithm': 'auto', 'metric': 'minkowski', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n      {'algorithm': 'auto', 'metric': 'minkowski', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n   {'algorithm': 'kd_tree', 'metric': 'manhattan', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n  {'algorithm': 'kd_tree', 'metric': 'manhattan', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n  {'algorithm': 'kd_tree', 'metric': 'manhattan', 'p': 2, 'weights': 'distance'}         0.606124        0.000058                1\n   {'algorithm': 'kd_tree', 'metric': 'manhattan', 'p': 2, 'weights': 'uniform'}         0.606124        0.000058                1\n{'algorithm': 'ball_tree', 'metric': 'minkowski', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n {'algorithm': 'ball_tree', 'metric': 'minkowski', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n{'algorithm': 'ball_tree', 'metric': 'manhattan', 'p': 2, 'weights': 'distance'}         0.606124        0.000058                1\n {'algorithm': 'ball_tree', 'metric': 'manhattan', 'p': 2, 'weights': 'uniform'}         0.606124        0.000058                1\n{'algorithm': 'ball_tree', 'metric': 'manhattan', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n {'algorithm': 'ball_tree', 'metric': 'manhattan', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n    {'algorithm': 'brute', 'metric': 'manhattan', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n     {'algorithm': 'brute', 'metric': 'manhattan', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n     {'algorithm': 'brute', 'metric': 'manhattan', 'p': 2, 'weights': 'uniform'}         0.606124        0.000058                1\n    {'algorithm': 'brute', 'metric': 'manhattan', 'p': 2, 'weights': 'distance'}         0.606124        0.000058                1\n     {'algorithm': 'brute', 'metric': 'minkowski', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n    {'algorithm': 'brute', 'metric': 'minkowski', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n  {'algorithm': 'kd_tree', 'metric': 'minkowski', 'p': 1, 'weights': 'distance'}         0.606124        0.000058                1\n   {'algorithm': 'kd_tree', 'metric': 'minkowski', 'p': 1, 'weights': 'uniform'}         0.606124        0.000058                1\n      {'algorithm': 'auto', 'metric': 'euclidean', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n     {'algorithm': 'auto', 'metric': 'euclidean', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\n{'algorithm': 'ball_tree', 'metric': 'euclidean', 'p': 1, 'weights': 'distance'}         0.511539        0.000846               25\n {'algorithm': 'ball_tree', 'metric': 'euclidean', 'p': 1, 'weights': 'uniform'}         0.511539        0.000846               25\n     {'algorithm': 'auto', 'metric': 'minkowski', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\n      {'algorithm': 'auto', 'metric': 'minkowski', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n     {'algorithm': 'auto', 'metric': 'euclidean', 'p': 1, 'weights': 'distance'}         0.511539        0.000846               25\n      {'algorithm': 'auto', 'metric': 'euclidean', 'p': 1, 'weights': 'uniform'}         0.511539        0.000846               25\n{'algorithm': 'ball_tree', 'metric': 'euclidean', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\n {'algorithm': 'ball_tree', 'metric': 'euclidean', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n   {'algorithm': 'kd_tree', 'metric': 'euclidean', 'p': 1, 'weights': 'uniform'}         0.511539        0.000846               25\n  {'algorithm': 'kd_tree', 'metric': 'euclidean', 'p': 1, 'weights': 'distance'}         0.511539        0.000846               25\n {'algorithm': 'ball_tree', 'metric': 'minkowski', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n{'algorithm': 'ball_tree', 'metric': 'minkowski', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\n   {'algorithm': 'kd_tree', 'metric': 'euclidean', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n  {'algorithm': 'kd_tree', 'metric': 'euclidean', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\n    {'algorithm': 'brute', 'metric': 'euclidean', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\n     {'algorithm': 'brute', 'metric': 'euclidean', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n    {'algorithm': 'brute', 'metric': 'euclidean', 'p': 1, 'weights': 'distance'}         0.511539        0.000846               25\n     {'algorithm': 'brute', 'metric': 'euclidean', 'p': 1, 'weights': 'uniform'}         0.511539        0.000846               25\n  {'algorithm': 'kd_tree', 'metric': 'minkowski', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\n   {'algorithm': 'kd_tree', 'metric': 'minkowski', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n     {'algorithm': 'brute', 'metric': 'minkowski', 'p': 2, 'weights': 'uniform'}         0.511539        0.000846               25\n    {'algorithm': 'brute', 'metric': 'minkowski', 'p': 2, 'weights': 'distance'}         0.511539        0.000846               25\nAkurasi model terbaik: 0.7089324618736383\n\nLaporan Klasifikasi:\n              precision    recall  f1-score   support\n\n           0       0.67      0.53      0.59       714\n           1       0.70      0.78      0.74       714\n           2       0.64      0.40      0.49       714\n           3       0.71      0.80      0.75       714\n           4       0.72      0.80      0.76       714\n           5       0.78      0.76      0.77       714\n           6       0.63      0.46      0.53       714\n           7       0.72      0.79      0.75       714\n           8       0.68      0.64      0.66       714\n           9       0.76      0.79      0.78       714\n          10       0.65      0.61      0.63       714\n          11       0.69      0.76      0.73       714\n          12       0.68      0.76      0.72       714\n          13       0.78      0.88      0.83       714\n          14       0.69      0.74      0.71       714\n          15       0.73      0.72      0.73       714\n          16       0.80      0.87      0.83       714\n          17       0.71      0.81      0.76       714\n          18       0.73      0.70      0.72       714\n          19       0.65      0.51      0.57       714\n          20       0.72      0.63      0.67       714\n          21       0.71      0.70      0.71       714\n          22       0.72      0.82      0.77       714\n          23       0.73      0.75      0.74       714\n          24       0.64      0.55      0.59       714\n          25       0.70      0.80      0.74       714\n          26       0.70      0.72      0.71       714\n          27       0.66      0.54      0.59       714\n          28       0.73      0.77      0.75       714\n          29       0.71      0.77      0.74       714\n          30       0.71      0.67      0.69       714\n          31       0.69      0.67      0.68       714\n          32       0.67      0.65      0.66       714\n          33       0.70      0.72      0.71       714\n          34       0.72      0.78      0.75       714\n          35       0.75      0.80      0.77       714\n          36       0.76      0.88      0.81       714\n          37       0.84      0.75      0.79       714\n          38       0.72      0.81      0.76       714\n          39       0.57      0.44      0.50       714\n          40       0.73      0.75      0.74       714\n          41       0.71      0.64      0.67       714\n          42       0.69      0.66      0.68       714\n          43       0.66      0.73      0.70       714\n          44       0.71      0.75      0.73       714\n\n    accuracy                           0.71     32130\n   macro avg       0.71      0.71      0.70     32130\nweighted avg       0.71      0.71      0.70     32130\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}