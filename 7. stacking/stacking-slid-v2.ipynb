{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8848659,"sourceType":"datasetVersion","datasetId":5326120},{"sourceId":72436,"sourceType":"modelInstanceVersion","modelInstanceId":60504}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-05T07:56:29.377255Z","iopub.execute_input":"2024-07-05T07:56:29.377689Z","iopub.status.idle":"2024-07-05T07:56:31.824486Z","shell.execute_reply.started":"2024-07-05T07:56:29.377625Z","shell.execute_reply":"2024-07-05T07:56:31.823258Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport joblib\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:31.826445Z","iopub.execute_input":"2024-07-05T07:56:31.826958Z","iopub.status.idle":"2024-07-05T07:56:31.833230Z","shell.execute_reply.started":"2024-07-05T07:56:31.826925Z","shell.execute_reply":"2024-07-05T07:56:31.831966Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, cv=3, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object\n        An object of that type which is cloned for each validation.\n        This object is assumed to implement the scikit-learn estimator interface.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features)\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Default is 5-fold cross-validation.\n\n    n_jobs : int or None, optional (default=None)\n        Number of jobs to run in parallel.\n        None means 1 unless in a joblib.parallel_backend context.\n        -1 means using all processors.\n\n    train_sizes : array-like, shape (n_ticks,), dtype float or int\n        Relative or absolute numbers of training examples that will be used to\n        generate the learning curve. If the dtype is float, it is regarded as a\n        fraction of the maximum size of the training set (that is determined\n        by the selected validation method), i.e. it has to be within (0, 1].\n        Otherwise it is interpreted as absolute sizes of the training sets.\n\n    scoring : string, callable or None, optional, default: None\n        A string (see model evaluation documentation) or a scorer callable object / function with\n        signature scorer(estimator, X, y).\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1, color=\"red\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"blue\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"red\", label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"blue\", label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:31.835134Z","iopub.execute_input":"2024-07-05T07:56:31.835495Z","iopub.status.idle":"2024-07-05T07:56:31.848032Z","shell.execute_reply.started":"2024-07-05T07:56:31.835457Z","shell.execute_reply":"2024-07-05T07:56:31.846786Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(r\"/kaggle/input/feature-common-language/audio_features_partial.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:31.850274Z","iopub.execute_input":"2024-07-05T07:56:31.850680Z","iopub.status.idle":"2024-07-05T07:56:33.152531Z","shell.execute_reply.started":"2024-07-05T07:56:31.850650Z","shell.execute_reply":"2024-07-05T07:56:33.151462Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n0     0.712224  0.055740        2989.050985         2193.800068   \n1     0.598403  0.074004        2372.315827         2065.561020   \n2     0.756316  0.046051        3274.178654         2196.474265   \n3     0.588983  0.061376        1948.418292         2049.242741   \n4     0.647222  0.069638        1705.618989         1824.714129   \n\n   spectral_rolloff  zero_crossing_rate     mfcc_1     mfcc_2     mfcc_3  \\\n0       5666.294643            0.275144 -202.32579  27.614292   4.094784   \n1       4795.649510            0.178041 -137.41476  59.931843   5.077963   \n2       5870.572917            0.353054 -233.02031  22.691550  10.057923   \n3       4186.921296            0.137682 -199.04490  80.806870  31.451380   \n4       3730.709877            0.095540 -325.47556  92.373820  17.725632   \n\n      mfcc_4  ...    mfcc_13   mfcc_14    mfcc_15   mfcc_16   mfcc_17  \\\n0   5.301181  ...   4.752774 -0.985637  -6.752584 -4.679379 -5.478848   \n1  -5.712012  ... -12.469353 -2.134825 -10.989368 -1.460541 -4.485021   \n2   3.829097  ...  -1.657243 -5.409642  -4.017134 -6.744406 -1.697630   \n3  -1.297673  ...  -4.202263  0.065943  -9.312079 -7.164060 -3.082040   \n4  31.867613  ...   3.169903  4.538502  -1.073114 -1.204524 -0.108214   \n\n    mfcc_18   mfcc_19   mfcc_20   label  \\\n0 -0.866508 -1.919669 -0.634521  Arabic   \n1 -0.408789 -8.211143 -5.170048  Arabic   \n2 -0.387302  0.829549  1.292110  Arabic   \n3 -8.046175 -3.083879 -2.018449  Arabic   \n4 -4.803460 -2.882802 -1.455632  Arabic   \n\n                                           file_path  \n0  /kaggle/input/preprocess-common-language/proce...  \n1  /kaggle/input/preprocess-common-language/proce...  \n2  /kaggle/input/preprocess-common-language/proce...  \n3  /kaggle/input/preprocess-common-language/proce...  \n4  /kaggle/input/preprocess-common-language/proce...  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chroma_stft</th>\n      <th>rms</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>spectral_rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc_1</th>\n      <th>mfcc_2</th>\n      <th>mfcc_3</th>\n      <th>mfcc_4</th>\n      <th>...</th>\n      <th>mfcc_13</th>\n      <th>mfcc_14</th>\n      <th>mfcc_15</th>\n      <th>mfcc_16</th>\n      <th>mfcc_17</th>\n      <th>mfcc_18</th>\n      <th>mfcc_19</th>\n      <th>mfcc_20</th>\n      <th>label</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.712224</td>\n      <td>0.055740</td>\n      <td>2989.050985</td>\n      <td>2193.800068</td>\n      <td>5666.294643</td>\n      <td>0.275144</td>\n      <td>-202.32579</td>\n      <td>27.614292</td>\n      <td>4.094784</td>\n      <td>5.301181</td>\n      <td>...</td>\n      <td>4.752774</td>\n      <td>-0.985637</td>\n      <td>-6.752584</td>\n      <td>-4.679379</td>\n      <td>-5.478848</td>\n      <td>-0.866508</td>\n      <td>-1.919669</td>\n      <td>-0.634521</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.598403</td>\n      <td>0.074004</td>\n      <td>2372.315827</td>\n      <td>2065.561020</td>\n      <td>4795.649510</td>\n      <td>0.178041</td>\n      <td>-137.41476</td>\n      <td>59.931843</td>\n      <td>5.077963</td>\n      <td>-5.712012</td>\n      <td>...</td>\n      <td>-12.469353</td>\n      <td>-2.134825</td>\n      <td>-10.989368</td>\n      <td>-1.460541</td>\n      <td>-4.485021</td>\n      <td>-0.408789</td>\n      <td>-8.211143</td>\n      <td>-5.170048</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.756316</td>\n      <td>0.046051</td>\n      <td>3274.178654</td>\n      <td>2196.474265</td>\n      <td>5870.572917</td>\n      <td>0.353054</td>\n      <td>-233.02031</td>\n      <td>22.691550</td>\n      <td>10.057923</td>\n      <td>3.829097</td>\n      <td>...</td>\n      <td>-1.657243</td>\n      <td>-5.409642</td>\n      <td>-4.017134</td>\n      <td>-6.744406</td>\n      <td>-1.697630</td>\n      <td>-0.387302</td>\n      <td>0.829549</td>\n      <td>1.292110</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.588983</td>\n      <td>0.061376</td>\n      <td>1948.418292</td>\n      <td>2049.242741</td>\n      <td>4186.921296</td>\n      <td>0.137682</td>\n      <td>-199.04490</td>\n      <td>80.806870</td>\n      <td>31.451380</td>\n      <td>-1.297673</td>\n      <td>...</td>\n      <td>-4.202263</td>\n      <td>0.065943</td>\n      <td>-9.312079</td>\n      <td>-7.164060</td>\n      <td>-3.082040</td>\n      <td>-8.046175</td>\n      <td>-3.083879</td>\n      <td>-2.018449</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.647222</td>\n      <td>0.069638</td>\n      <td>1705.618989</td>\n      <td>1824.714129</td>\n      <td>3730.709877</td>\n      <td>0.095540</td>\n      <td>-325.47556</td>\n      <td>92.373820</td>\n      <td>17.725632</td>\n      <td>31.867613</td>\n      <td>...</td>\n      <td>3.169903</td>\n      <td>4.538502</td>\n      <td>-1.073114</td>\n      <td>-1.204524</td>\n      <td>-0.108214</td>\n      <td>-4.803460</td>\n      <td>-2.882802</td>\n      <td>-1.455632</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit LabelEncoder with your actual labels\nlabel_encoder.fit(df['label'])\n\n# Transform actual labels to numeric labels\ndf['numeric_labels'] = label_encoder.transform(df['label'])","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:33.153735Z","iopub.execute_input":"2024-07-05T07:56:33.154070Z","iopub.status.idle":"2024-07-05T07:56:33.181311Z","shell.execute_reply.started":"2024-07-05T07:56:33.154042Z","shell.execute_reply":"2024-07-05T07:56:33.180074Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['label','numeric_labels','file_path'])\ny = df['numeric_labels']","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:33.182697Z","iopub.execute_input":"2024-07-05T07:56:33.183106Z","iopub.status.idle":"2024-07-05T07:56:33.194613Z","shell.execute_reply.started":"2024-07-05T07:56:33.183075Z","shell.execute_reply":"2024-07-05T07:56:33.193340Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:33.195753Z","iopub.execute_input":"2024-07-05T07:56:33.196115Z","iopub.status.idle":"2024-07-05T07:56:34.844359Z","shell.execute_reply.started":"2024-07-05T07:56:33.196086Z","shell.execute_reply":"2024-07-05T07:56:34.843111Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\n# Jumlah kelas sebelum SMOTE\nprint(\"Jumlah kelas sebelum SMOTE:\")\nprint(Counter(y))\n\n# Jumlah kelas setelah SMOTE\nprint(\"\\nJumlah kelas setelah SMOTE:\")\nprint(Counter(y_resampled))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:34.845845Z","iopub.execute_input":"2024-07-05T07:56:34.846334Z","iopub.status.idle":"2024-07-05T07:56:34.889138Z","shell.execute_reply.started":"2024-07-05T07:56:34.846301Z","shell.execute_reply":"2024-07-05T07:56:34.887919Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Jumlah kelas sebelum SMOTE:\nCounter({2: 3570, 39: 3177, 19: 3012, 6: 3003, 27: 2955, 41: 2784, 24: 2766, 0: 2751, 20: 2733, 37: 2691, 10: 2550, 33: 2547, 18: 2520, 21: 2484, 42: 2472, 8: 2442, 40: 2367, 26: 2331, 30: 2283, 28: 2277, 23: 2268, 32: 2238, 7: 2202, 31: 2196, 43: 2181, 15: 2073, 44: 2073, 5: 2016, 34: 1977, 9: 1962, 25: 1947, 12: 1932, 1: 1914, 16: 1890, 29: 1884, 14: 1863, 3: 1830, 17: 1830, 4: 1797, 11: 1773, 35: 1758, 36: 1752, 38: 1737, 22: 1695, 13: 1623})\n\nJumlah kelas setelah SMOTE:\nCounter({0: 3570, 4: 3570, 9: 3570, 27: 3570, 18: 3570, 24: 3570, 23: 3570, 13: 3570, 20: 3570, 11: 3570, 16: 3570, 40: 3570, 28: 3570, 15: 3570, 21: 3570, 8: 3570, 31: 3570, 29: 3570, 5: 3570, 7: 3570, 41: 3570, 44: 3570, 3: 3570, 2: 3570, 14: 3570, 43: 3570, 36: 3570, 26: 3570, 34: 3570, 12: 3570, 37: 3570, 35: 3570, 42: 3570, 33: 3570, 17: 3570, 25: 3570, 6: 3570, 30: 3570, 39: 3570, 22: 3570, 10: 3570, 1: 3570, 19: 3570, 32: 3570, 38: 3570})\n","output_type":"stream"}]},{"cell_type":"code","source":"### split data 80% 20%\n\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,\n                                                    test_size=0.2, random_state=42,\n                                                    stratify=y_resampled)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:34.892676Z","iopub.execute_input":"2024-07-05T07:56:34.893994Z","iopub.status.idle":"2024-07-05T07:56:35.034593Z","shell.execute_reply.started":"2024-07-05T07:56:34.893943Z","shell.execute_reply":"2024-07-05T07:56:35.033281Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Inisialisasi StandardScaler\nscaler = StandardScaler()\n\n# Fit scaler pada data training dan transform kedua set data\nX_train_normalized = scaler.fit_transform(X_train)\nX_test_normalized = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:35.036231Z","iopub.execute_input":"2024-07-05T07:56:35.036737Z","iopub.status.idle":"2024-07-05T07:56:35.125274Z","shell.execute_reply.started":"2024-07-05T07:56:35.036696Z","shell.execute_reply":"2024-07-05T07:56:35.124030Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X_train_normalized)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:35.126717Z","iopub.execute_input":"2024-07-05T07:56:35.127113Z","iopub.status.idle":"2024-07-05T07:56:35.165074Z","shell.execute_reply.started":"2024-07-05T07:56:35.127081Z","shell.execute_reply":"2024-07-05T07:56:35.163590Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"              0         1         2         3         4         5         6   \\\n0      -0.125270 -0.462618 -0.063722  0.962710  0.546778 -0.530245 -0.215304   \n1      -0.447086 -0.164635 -0.081286  0.298297  0.031393 -0.255482  0.851859   \n2      -0.136721  0.693945 -0.652197  0.593003 -0.029296 -1.373536  0.804041   \n3      -1.041236  1.421366 -0.560796  0.131813 -0.337850 -0.264703  0.680879   \n4      -0.923043 -0.815273  0.428687  0.336918  0.459523  0.063171  0.295056   \n...          ...       ...       ...       ...       ...       ...       ...   \n128515 -1.069659  0.820296 -1.411504 -1.652472 -1.413538 -0.950462 -2.531171   \n128516  0.000360 -0.463296 -0.023205  0.176157 -0.034989 -0.226584  0.809894   \n128517 -2.370420  1.866536 -1.352947 -1.059491 -1.572022 -0.799900 -0.373726   \n128518  0.146890 -0.653630  0.677426  0.721152  0.754992  0.370645  0.048390   \n128519 -0.280134 -0.703109  0.021005  0.566020  0.206863 -0.449980 -0.051016   \n\n              7         8         9   ...        16        17        18  \\\n0      -0.176643  1.412404  0.383635  ...  0.193716  0.060471  0.656303   \n1      -0.201491 -0.137365  0.157049  ... -1.101902 -1.626334  0.223691   \n2       0.107182  0.606830  0.598271  ... -0.054259 -1.238785 -1.046840   \n3      -0.053193  0.069079  0.717965  ... -1.921328  0.441973  0.176668   \n4      -0.775594 -1.244932 -2.012682  ...  0.224048  0.497766  0.512246   \n...          ...       ...       ...  ...       ...       ...       ...   \n128515  1.026397 -0.282676  2.174811  ... -1.828143  0.285871  0.049287   \n128516 -0.064593 -0.741426 -1.760898  ...  0.442690  0.649209 -0.596835   \n128517  1.257349  0.578946  0.872449  ...  0.865331 -0.488842  0.075970   \n128518 -0.953738  0.222994  0.610338  ... -0.512452 -1.230825  0.102356   \n128519 -0.075521  0.300568 -0.216127  ... -0.123118 -0.241533  0.031778   \n\n              19        20        21        22        23        24        25  \n0      -0.022266  0.317852 -0.352507 -1.010202 -1.367641 -1.260068 -1.444051  \n1       0.817619 -1.296437 -0.614610 -0.134165 -3.339167 -0.671473  0.503199  \n2      -2.431179 -2.554992 -2.492506 -0.366025 -0.626432  0.076768  0.491064  \n3      -2.161943  0.177355  0.315965 -1.888467  0.640302  0.116856 -1.150069  \n4      -0.309098 -0.438342  0.097450  0.281906  0.694139  0.955619 -1.263811  \n...          ...       ...       ...       ...       ...       ...       ...  \n128515  0.720958  0.020781 -1.278091 -0.628007  0.212564 -1.642634 -2.222433  \n128516 -1.256466 -0.773914 -1.425531 -1.128419 -0.704997 -0.171163  0.474619  \n128517  0.050136 -1.373727  0.271099 -0.194054 -0.750243 -1.434839  0.372517  \n128518  0.297172 -0.461706 -1.169560 -0.183656  0.060295  0.011697  0.617881  \n128519  0.275208  1.477354  1.799078  2.096360  1.079606  0.597507  0.833435  \n\n[128520 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.125270</td>\n      <td>-0.462618</td>\n      <td>-0.063722</td>\n      <td>0.962710</td>\n      <td>0.546778</td>\n      <td>-0.530245</td>\n      <td>-0.215304</td>\n      <td>-0.176643</td>\n      <td>1.412404</td>\n      <td>0.383635</td>\n      <td>...</td>\n      <td>0.193716</td>\n      <td>0.060471</td>\n      <td>0.656303</td>\n      <td>-0.022266</td>\n      <td>0.317852</td>\n      <td>-0.352507</td>\n      <td>-1.010202</td>\n      <td>-1.367641</td>\n      <td>-1.260068</td>\n      <td>-1.444051</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.447086</td>\n      <td>-0.164635</td>\n      <td>-0.081286</td>\n      <td>0.298297</td>\n      <td>0.031393</td>\n      <td>-0.255482</td>\n      <td>0.851859</td>\n      <td>-0.201491</td>\n      <td>-0.137365</td>\n      <td>0.157049</td>\n      <td>...</td>\n      <td>-1.101902</td>\n      <td>-1.626334</td>\n      <td>0.223691</td>\n      <td>0.817619</td>\n      <td>-1.296437</td>\n      <td>-0.614610</td>\n      <td>-0.134165</td>\n      <td>-3.339167</td>\n      <td>-0.671473</td>\n      <td>0.503199</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.136721</td>\n      <td>0.693945</td>\n      <td>-0.652197</td>\n      <td>0.593003</td>\n      <td>-0.029296</td>\n      <td>-1.373536</td>\n      <td>0.804041</td>\n      <td>0.107182</td>\n      <td>0.606830</td>\n      <td>0.598271</td>\n      <td>...</td>\n      <td>-0.054259</td>\n      <td>-1.238785</td>\n      <td>-1.046840</td>\n      <td>-2.431179</td>\n      <td>-2.554992</td>\n      <td>-2.492506</td>\n      <td>-0.366025</td>\n      <td>-0.626432</td>\n      <td>0.076768</td>\n      <td>0.491064</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.041236</td>\n      <td>1.421366</td>\n      <td>-0.560796</td>\n      <td>0.131813</td>\n      <td>-0.337850</td>\n      <td>-0.264703</td>\n      <td>0.680879</td>\n      <td>-0.053193</td>\n      <td>0.069079</td>\n      <td>0.717965</td>\n      <td>...</td>\n      <td>-1.921328</td>\n      <td>0.441973</td>\n      <td>0.176668</td>\n      <td>-2.161943</td>\n      <td>0.177355</td>\n      <td>0.315965</td>\n      <td>-1.888467</td>\n      <td>0.640302</td>\n      <td>0.116856</td>\n      <td>-1.150069</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.923043</td>\n      <td>-0.815273</td>\n      <td>0.428687</td>\n      <td>0.336918</td>\n      <td>0.459523</td>\n      <td>0.063171</td>\n      <td>0.295056</td>\n      <td>-0.775594</td>\n      <td>-1.244932</td>\n      <td>-2.012682</td>\n      <td>...</td>\n      <td>0.224048</td>\n      <td>0.497766</td>\n      <td>0.512246</td>\n      <td>-0.309098</td>\n      <td>-0.438342</td>\n      <td>0.097450</td>\n      <td>0.281906</td>\n      <td>0.694139</td>\n      <td>0.955619</td>\n      <td>-1.263811</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>128515</th>\n      <td>-1.069659</td>\n      <td>0.820296</td>\n      <td>-1.411504</td>\n      <td>-1.652472</td>\n      <td>-1.413538</td>\n      <td>-0.950462</td>\n      <td>-2.531171</td>\n      <td>1.026397</td>\n      <td>-0.282676</td>\n      <td>2.174811</td>\n      <td>...</td>\n      <td>-1.828143</td>\n      <td>0.285871</td>\n      <td>0.049287</td>\n      <td>0.720958</td>\n      <td>0.020781</td>\n      <td>-1.278091</td>\n      <td>-0.628007</td>\n      <td>0.212564</td>\n      <td>-1.642634</td>\n      <td>-2.222433</td>\n    </tr>\n    <tr>\n      <th>128516</th>\n      <td>0.000360</td>\n      <td>-0.463296</td>\n      <td>-0.023205</td>\n      <td>0.176157</td>\n      <td>-0.034989</td>\n      <td>-0.226584</td>\n      <td>0.809894</td>\n      <td>-0.064593</td>\n      <td>-0.741426</td>\n      <td>-1.760898</td>\n      <td>...</td>\n      <td>0.442690</td>\n      <td>0.649209</td>\n      <td>-0.596835</td>\n      <td>-1.256466</td>\n      <td>-0.773914</td>\n      <td>-1.425531</td>\n      <td>-1.128419</td>\n      <td>-0.704997</td>\n      <td>-0.171163</td>\n      <td>0.474619</td>\n    </tr>\n    <tr>\n      <th>128517</th>\n      <td>-2.370420</td>\n      <td>1.866536</td>\n      <td>-1.352947</td>\n      <td>-1.059491</td>\n      <td>-1.572022</td>\n      <td>-0.799900</td>\n      <td>-0.373726</td>\n      <td>1.257349</td>\n      <td>0.578946</td>\n      <td>0.872449</td>\n      <td>...</td>\n      <td>0.865331</td>\n      <td>-0.488842</td>\n      <td>0.075970</td>\n      <td>0.050136</td>\n      <td>-1.373727</td>\n      <td>0.271099</td>\n      <td>-0.194054</td>\n      <td>-0.750243</td>\n      <td>-1.434839</td>\n      <td>0.372517</td>\n    </tr>\n    <tr>\n      <th>128518</th>\n      <td>0.146890</td>\n      <td>-0.653630</td>\n      <td>0.677426</td>\n      <td>0.721152</td>\n      <td>0.754992</td>\n      <td>0.370645</td>\n      <td>0.048390</td>\n      <td>-0.953738</td>\n      <td>0.222994</td>\n      <td>0.610338</td>\n      <td>...</td>\n      <td>-0.512452</td>\n      <td>-1.230825</td>\n      <td>0.102356</td>\n      <td>0.297172</td>\n      <td>-0.461706</td>\n      <td>-1.169560</td>\n      <td>-0.183656</td>\n      <td>0.060295</td>\n      <td>0.011697</td>\n      <td>0.617881</td>\n    </tr>\n    <tr>\n      <th>128519</th>\n      <td>-0.280134</td>\n      <td>-0.703109</td>\n      <td>0.021005</td>\n      <td>0.566020</td>\n      <td>0.206863</td>\n      <td>-0.449980</td>\n      <td>-0.051016</td>\n      <td>-0.075521</td>\n      <td>0.300568</td>\n      <td>-0.216127</td>\n      <td>...</td>\n      <td>-0.123118</td>\n      <td>-0.241533</td>\n      <td>0.031778</td>\n      <td>0.275208</td>\n      <td>1.477354</td>\n      <td>1.799078</td>\n      <td>2.096360</td>\n      <td>1.079606</td>\n      <td>0.597507</td>\n      <td>0.833435</td>\n    </tr>\n  </tbody>\n</table>\n<p>128520 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:35.166758Z","iopub.execute_input":"2024-07-05T07:56:35.167239Z","iopub.status.idle":"2024-07-05T07:56:35.173744Z","shell.execute_reply.started":"2024-07-05T07:56:35.167197Z","shell.execute_reply":"2024-07-05T07:56:35.172638Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, StackingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\n\n# Membuat model-model dasar\nrf = RandomForestClassifier(\n    n_estimators=200,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    max_features='log2',\n    max_depth=None,\n    bootstrap=False,\n    random_state=42\n)\n\nknn = KNeighborsClassifier(\n    n_neighbors=1,\n    algorithm='auto', \n    metric='manhattan', \n    p=2, \n    weights='distance'\n)\n\ndt = DecisionTreeClassifier(\n    criterion='entropy', \n    max_depth=None, \n    max_features=None, \n    min_samples_leaf=1, \n    min_samples_split=2\n)\n\n# Membuat ensemble stacking\nestimators = [\n    ('rf', rf),\n    ('knn', knn),\n    ('dt', dt)\n]\n\nstacking_model = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(multi_class='multinomial', max_iter=1000),\n    cv=3\n)\n\n# Melatih model dengan data yang telah dinormalisasi\nstacking_model.fit(X_train_normalized, y_train)\n\n# Membuat prediksi dengan data pengujian yang telah dinormalisasi\ny_pred = stacking_model.predict(X_test_normalized)\n\n# Menghitung akurasi\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Akurasi model stacking: {accuracy:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T07:56:35.176253Z","iopub.execute_input":"2024-07-05T07:56:35.176623Z","iopub.status.idle":"2024-07-05T08:48:17.397100Z","shell.execute_reply.started":"2024-07-05T07:56:35.176590Z","shell.execute_reply":"2024-07-05T08:48:17.394700Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Akurasi model stacking: 0.87395\n","output_type":"stream"}]},{"cell_type":"code","source":"stacking_model.score(X_train_normalized,y_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T08:49:46.831193Z","iopub.execute_input":"2024-07-05T08:49:46.831939Z","iopub.status.idle":"2024-07-05T08:55:02.451527Z","shell.execute_reply.started":"2024-07-05T08:49:46.831878Z","shell.execute_reply":"2024-07-05T08:55:02.450004Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Generate and print classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T09:01:25.137772Z","iopub.execute_input":"2024-07-05T09:01:25.138257Z","iopub.status.idle":"2024-07-05T09:01:25.255387Z","shell.execute_reply.started":"2024-07-05T09:01:25.138221Z","shell.execute_reply":"2024-07-05T09:01:25.253900Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.80      0.84       714\n           1       0.84      0.90      0.87       714\n           2       0.93      0.83      0.88       714\n           3       0.85      0.87      0.86       714\n           4       0.89      0.87      0.88       714\n           5       0.88      0.84      0.86       714\n           6       0.87      0.72      0.78       714\n           7       0.87      0.95      0.91       714\n           8       0.89      0.86      0.87       714\n           9       0.90      0.92      0.91       714\n          10       0.88      0.82      0.85       714\n          11       0.85      0.83      0.84       714\n          12       0.82      0.87      0.85       714\n          13       0.89      0.93      0.91       714\n          14       0.89      0.86      0.88       714\n          15       0.88      0.92      0.90       714\n          16       0.92      0.97      0.94       714\n          17       0.87      0.86      0.87       714\n          18       0.89      0.91      0.90       714\n          19       0.86      0.88      0.87       714\n          20       0.94      0.89      0.91       714\n          21       0.90      0.91      0.90       714\n          22       0.86      0.88      0.87       714\n          23       0.89      0.90      0.90       714\n          24       0.88      0.74      0.80       714\n          25       0.84      0.89      0.87       714\n          26       0.86      0.91      0.88       714\n          27       0.92      0.86      0.89       714\n          28       0.88      0.93      0.90       714\n          29       0.85      0.90      0.88       714\n          30       0.84      0.78      0.81       714\n          31       0.84      0.79      0.82       714\n          32       0.82      0.81      0.82       714\n          33       0.87      0.93      0.90       714\n          34       0.86      0.95      0.90       714\n          35       0.87      0.86      0.87       714\n          36       0.86      0.96      0.91       714\n          37       0.97      0.95      0.96       714\n          38       0.86      0.87      0.86       714\n          39       0.89      0.83      0.86       714\n          40       0.88      0.92      0.90       714\n          41       0.88      0.85      0.87       714\n          42       0.85      0.84      0.85       714\n          43       0.83      0.89      0.86       714\n          44       0.85      0.86      0.85       714\n\n    accuracy                           0.87     32130\n   macro avg       0.87      0.87      0.87     32130\nweighted avg       0.87      0.87      0.87     32130\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}