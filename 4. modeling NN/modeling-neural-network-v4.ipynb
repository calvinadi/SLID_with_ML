{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8848655,"sourceType":"datasetVersion","datasetId":5326116}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-03T15:17:46.305881Z","iopub.execute_input":"2024-07-03T15:17:46.306168Z","iopub.status.idle":"2024-07-03T15:17:47.139586Z","shell.execute_reply.started":"2024-07-03T15:17:46.306132Z","shell.execute_reply":"2024-07-03T15:17:47.138375Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport joblib\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:47.141068Z","iopub.execute_input":"2024-07-03T15:17:47.141691Z","iopub.status.idle":"2024-07-03T15:17:47.147779Z","shell.execute_reply.started":"2024-07-03T15:17:47.141650Z","shell.execute_reply":"2024-07-03T15:17:47.146722Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(r\"/kaggle/input/feature-common-language/audio_features_partial.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:47.149156Z","iopub.execute_input":"2024-07-03T15:17:47.150173Z","iopub.status.idle":"2024-07-03T15:17:47.940950Z","shell.execute_reply.started":"2024-07-03T15:17:47.150137Z","shell.execute_reply":"2024-07-03T15:17:47.939780Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n0     0.712224  0.055740        2989.050985         2193.800068   \n1     0.598403  0.074004        2372.315827         2065.561020   \n2     0.756316  0.046051        3274.178654         2196.474265   \n3     0.588983  0.061376        1948.418292         2049.242741   \n4     0.647222  0.069638        1705.618989         1824.714129   \n\n   spectral_rolloff  zero_crossing_rate     mfcc_1     mfcc_2     mfcc_3  \\\n0       5666.294643            0.275144 -202.32579  27.614292   4.094784   \n1       4795.649510            0.178041 -137.41476  59.931843   5.077963   \n2       5870.572917            0.353054 -233.02031  22.691550  10.057923   \n3       4186.921296            0.137682 -199.04490  80.806870  31.451380   \n4       3730.709877            0.095540 -325.47556  92.373820  17.725632   \n\n      mfcc_4  ...    mfcc_13   mfcc_14    mfcc_15   mfcc_16   mfcc_17  \\\n0   5.301181  ...   4.752774 -0.985637  -6.752584 -4.679379 -5.478848   \n1  -5.712012  ... -12.469353 -2.134825 -10.989368 -1.460541 -4.485021   \n2   3.829097  ...  -1.657243 -5.409642  -4.017134 -6.744406 -1.697630   \n3  -1.297673  ...  -4.202263  0.065943  -9.312079 -7.164060 -3.082040   \n4  31.867613  ...   3.169903  4.538502  -1.073114 -1.204524 -0.108214   \n\n    mfcc_18   mfcc_19   mfcc_20   label  \\\n0 -0.866508 -1.919669 -0.634521  Arabic   \n1 -0.408789 -8.211143 -5.170048  Arabic   \n2 -0.387302  0.829549  1.292110  Arabic   \n3 -8.046175 -3.083879 -2.018449  Arabic   \n4 -4.803460 -2.882802 -1.455632  Arabic   \n\n                                           file_path  \n0  /kaggle/input/preprocess-common-language/proce...  \n1  /kaggle/input/preprocess-common-language/proce...  \n2  /kaggle/input/preprocess-common-language/proce...  \n3  /kaggle/input/preprocess-common-language/proce...  \n4  /kaggle/input/preprocess-common-language/proce...  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chroma_stft</th>\n      <th>rms</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>spectral_rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc_1</th>\n      <th>mfcc_2</th>\n      <th>mfcc_3</th>\n      <th>mfcc_4</th>\n      <th>...</th>\n      <th>mfcc_13</th>\n      <th>mfcc_14</th>\n      <th>mfcc_15</th>\n      <th>mfcc_16</th>\n      <th>mfcc_17</th>\n      <th>mfcc_18</th>\n      <th>mfcc_19</th>\n      <th>mfcc_20</th>\n      <th>label</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.712224</td>\n      <td>0.055740</td>\n      <td>2989.050985</td>\n      <td>2193.800068</td>\n      <td>5666.294643</td>\n      <td>0.275144</td>\n      <td>-202.32579</td>\n      <td>27.614292</td>\n      <td>4.094784</td>\n      <td>5.301181</td>\n      <td>...</td>\n      <td>4.752774</td>\n      <td>-0.985637</td>\n      <td>-6.752584</td>\n      <td>-4.679379</td>\n      <td>-5.478848</td>\n      <td>-0.866508</td>\n      <td>-1.919669</td>\n      <td>-0.634521</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.598403</td>\n      <td>0.074004</td>\n      <td>2372.315827</td>\n      <td>2065.561020</td>\n      <td>4795.649510</td>\n      <td>0.178041</td>\n      <td>-137.41476</td>\n      <td>59.931843</td>\n      <td>5.077963</td>\n      <td>-5.712012</td>\n      <td>...</td>\n      <td>-12.469353</td>\n      <td>-2.134825</td>\n      <td>-10.989368</td>\n      <td>-1.460541</td>\n      <td>-4.485021</td>\n      <td>-0.408789</td>\n      <td>-8.211143</td>\n      <td>-5.170048</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.756316</td>\n      <td>0.046051</td>\n      <td>3274.178654</td>\n      <td>2196.474265</td>\n      <td>5870.572917</td>\n      <td>0.353054</td>\n      <td>-233.02031</td>\n      <td>22.691550</td>\n      <td>10.057923</td>\n      <td>3.829097</td>\n      <td>...</td>\n      <td>-1.657243</td>\n      <td>-5.409642</td>\n      <td>-4.017134</td>\n      <td>-6.744406</td>\n      <td>-1.697630</td>\n      <td>-0.387302</td>\n      <td>0.829549</td>\n      <td>1.292110</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.588983</td>\n      <td>0.061376</td>\n      <td>1948.418292</td>\n      <td>2049.242741</td>\n      <td>4186.921296</td>\n      <td>0.137682</td>\n      <td>-199.04490</td>\n      <td>80.806870</td>\n      <td>31.451380</td>\n      <td>-1.297673</td>\n      <td>...</td>\n      <td>-4.202263</td>\n      <td>0.065943</td>\n      <td>-9.312079</td>\n      <td>-7.164060</td>\n      <td>-3.082040</td>\n      <td>-8.046175</td>\n      <td>-3.083879</td>\n      <td>-2.018449</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.647222</td>\n      <td>0.069638</td>\n      <td>1705.618989</td>\n      <td>1824.714129</td>\n      <td>3730.709877</td>\n      <td>0.095540</td>\n      <td>-325.47556</td>\n      <td>92.373820</td>\n      <td>17.725632</td>\n      <td>31.867613</td>\n      <td>...</td>\n      <td>3.169903</td>\n      <td>4.538502</td>\n      <td>-1.073114</td>\n      <td>-1.204524</td>\n      <td>-0.108214</td>\n      <td>-4.803460</td>\n      <td>-2.882802</td>\n      <td>-1.455632</td>\n      <td>Arabic</td>\n      <td>/kaggle/input/preprocess-common-language/proce...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:47.944588Z","iopub.execute_input":"2024-07-03T15:17:47.945016Z","iopub.status.idle":"2024-07-03T15:17:48.136774Z","shell.execute_reply.started":"2024-07-03T15:17:47.944988Z","shell.execute_reply":"2024-07-03T15:17:48.135591Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit LabelEncoder with your actual labels\nlabel_encoder.fit(df['label'])\n\n# Transform actual labels to numeric labels\ndf['numeric_labels'] = label_encoder.transform(df['label'])","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:48.138052Z","iopub.execute_input":"2024-07-03T15:17:48.138419Z","iopub.status.idle":"2024-07-03T15:17:48.169836Z","shell.execute_reply.started":"2024-07-03T15:17:48.138386Z","shell.execute_reply":"2024-07-03T15:17:48.168740Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['label','numeric_labels','file_path'])\ny = df['numeric_labels']","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:48.171151Z","iopub.execute_input":"2024-07-03T15:17:48.171544Z","iopub.status.idle":"2024-07-03T15:17:48.185924Z","shell.execute_reply.started":"2024-07-03T15:17:48.171505Z","shell.execute_reply":"2024-07-03T15:17:48.184949Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:48.187189Z","iopub.execute_input":"2024-07-03T15:17:48.187539Z","iopub.status.idle":"2024-07-03T15:17:50.458365Z","shell.execute_reply.started":"2024-07-03T15:17:48.187505Z","shell.execute_reply":"2024-07-03T15:17:50.457531Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\n# Jumlah kelas sebelum SMOTE\nprint(\"Jumlah kelas sebelum SMOTE:\")\nprint(Counter(y))\n\n# Jumlah kelas setelah SMOTE\nprint(\"\\nJumlah kelas setelah SMOTE:\")\nprint(Counter(y_resampled))","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:50.459693Z","iopub.execute_input":"2024-07-03T15:17:50.460671Z","iopub.status.idle":"2024-07-03T15:17:50.509880Z","shell.execute_reply.started":"2024-07-03T15:17:50.460625Z","shell.execute_reply":"2024-07-03T15:17:50.508862Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Jumlah kelas sebelum SMOTE:\nCounter({2: 3570, 39: 3177, 19: 3012, 6: 3003, 27: 2955, 41: 2784, 24: 2766, 0: 2751, 20: 2733, 37: 2691, 10: 2550, 33: 2547, 18: 2520, 21: 2484, 42: 2472, 8: 2442, 40: 2367, 26: 2331, 30: 2283, 28: 2277, 23: 2268, 32: 2238, 7: 2202, 31: 2196, 43: 2181, 15: 2073, 44: 2073, 5: 2016, 34: 1977, 9: 1962, 25: 1947, 12: 1932, 1: 1914, 16: 1890, 29: 1884, 14: 1863, 3: 1830, 17: 1830, 4: 1797, 11: 1773, 35: 1758, 36: 1752, 38: 1737, 22: 1695, 13: 1623})\n\nJumlah kelas setelah SMOTE:\nCounter({0: 3570, 4: 3570, 9: 3570, 27: 3570, 18: 3570, 24: 3570, 23: 3570, 13: 3570, 20: 3570, 11: 3570, 16: 3570, 40: 3570, 28: 3570, 15: 3570, 21: 3570, 8: 3570, 31: 3570, 29: 3570, 5: 3570, 7: 3570, 41: 3570, 44: 3570, 3: 3570, 2: 3570, 14: 3570, 43: 3570, 36: 3570, 26: 3570, 34: 3570, 12: 3570, 37: 3570, 35: 3570, 42: 3570, 33: 3570, 17: 3570, 25: 3570, 6: 3570, 30: 3570, 39: 3570, 22: 3570, 10: 3570, 1: 3570, 19: 3570, 32: 3570, 38: 3570})\n","output_type":"stream"}]},{"cell_type":"code","source":"### split data 80% 20%\n\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,\n                                                    test_size=0.2, random_state=42,\n                                                    stratify=y_resampled)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:50.511311Z","iopub.execute_input":"2024-07-03T15:17:50.511598Z","iopub.status.idle":"2024-07-03T15:17:50.637594Z","shell.execute_reply.started":"2024-07-03T15:17:50.511571Z","shell.execute_reply":"2024-07-03T15:17:50.636752Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.regularizers import l1_l2","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:50.638859Z","iopub.execute_input":"2024-07-03T15:17:50.639529Z","iopub.status.idle":"2024-07-03T15:17:53.845094Z","shell.execute_reply.started":"2024-07-03T15:17:50.639491Z","shell.execute_reply":"2024-07-03T15:17:53.844264Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2024-07-03 15:17:50.993095: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-03 15:17:50.993158: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-03 15:17:50.995156: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"num_classes = len(label_encoder.classes_)\ninput_dim=X_train.shape[1]\n\nmodel = Sequential([\n    Input(shape=(input_dim,)),\n    \n    Dense(512, kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001)),\n    BatchNormalization(),\n    LeakyReLU(alpha=0.1),\n    Dropout(0.3),\n    \n    Dense(256, kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001)),\n    BatchNormalization(),\n    LeakyReLU(alpha=0.1),\n    Dropout(0.3),\n    \n    Dense(128, kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001)),\n    BatchNormalization(),\n    LeakyReLU(alpha=0.1),\n    Dropout(0.3),\n    \n    Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:53.846405Z","iopub.execute_input":"2024-07-03T15:17:53.846930Z","iopub.status.idle":"2024-07-03T15:17:54.534034Z","shell.execute_reply.started":"2024-07-03T15:17:53.846901Z","shell.execute_reply":"2024-07-03T15:17:54.533135Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m13,824\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)             │         \u001b[38;5;34m5,805\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,805</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,437\u001b[0m (732.18 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,437</span> (732.18 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,645\u001b[0m (725.18 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,645</span> (725.18 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport datetime\n\n\n# Membuat callback EarlyStopping\nearly_stopping = EarlyStopping(\n    monitor='val_loss', \n    patience=10,         \n    restore_best_weights=True, \n    verbose=1\n)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=0.000001, verbose=1)\n\nmodel_checkpoint = ModelCheckpoint('best_model.keras', \n                                   save_best_only=True, \n                                   monitor='val_accuracy',\n                                   mode='max', \n                                   verbose=1)\n\nlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test,y_test),\n    epochs=200,\n    batch_size=32,\n    callbacks=[early_stopping, reduce_lr, model_checkpoint, tensorboard_callback],\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:17:54.535211Z","iopub.execute_input":"2024-07-03T15:17:54.535505Z","iopub.status.idle":"2024-07-03T15:55:24.561130Z","shell.execute_reply.started":"2024-07-03T15:17:54.535478Z","shell.execute_reply":"2024-07-03T15:55:24.560101Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/200\n\u001b[1m  33/4017\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.0122 - loss: 5.2676  ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1720019883.173188    5035 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1720019883.188714    5035 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0287 - loss: 4.8964","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720019900.390555    5035 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.07971, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.0287 - loss: 4.8963 - val_accuracy: 0.0797 - val_loss: 4.4066 - learning_rate: 1.0000e-04\nEpoch 2/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0592 - loss: 4.4229\nEpoch 2: val_accuracy improved from 0.07971 to 0.08774, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.0593 - loss: 4.4226 - val_accuracy: 0.0877 - val_loss: 4.1542 - learning_rate: 1.0000e-04\nEpoch 3/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0896 - loss: 4.1458\nEpoch 3: val_accuracy improved from 0.08774 to 0.09471, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.0896 - loss: 4.1456 - val_accuracy: 0.0947 - val_loss: 4.0545 - learning_rate: 1.0000e-04\nEpoch 4/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1127 - loss: 3.9513\nEpoch 4: val_accuracy improved from 0.09471 to 0.12176, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1127 - loss: 3.9511 - val_accuracy: 0.1218 - val_loss: 3.8593 - learning_rate: 1.0000e-04\nEpoch 5/200\n\u001b[1m4016/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1285 - loss: 3.8170\nEpoch 5: val_accuracy improved from 0.12176 to 0.14653, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1285 - loss: 3.8170 - val_accuracy: 0.1465 - val_loss: 3.6946 - learning_rate: 1.0000e-04\nEpoch 6/200\n\u001b[1m4011/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1409 - loss: 3.7109\nEpoch 6: val_accuracy did not improve from 0.14653\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1409 - loss: 3.7109 - val_accuracy: 0.1462 - val_loss: 3.6623 - learning_rate: 1.0000e-04\nEpoch 7/200\n\u001b[1m4008/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1482 - loss: 3.6368\nEpoch 7: val_accuracy improved from 0.14653 to 0.15235, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1482 - loss: 3.6367 - val_accuracy: 0.1523 - val_loss: 3.5956 - learning_rate: 1.0000e-04\nEpoch 8/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1575 - loss: 3.5629\nEpoch 8: val_accuracy improved from 0.15235 to 0.16499, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1575 - loss: 3.5628 - val_accuracy: 0.1650 - val_loss: 3.5032 - learning_rate: 1.0000e-04\nEpoch 9/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1677 - loss: 3.5139\nEpoch 9: val_accuracy did not improve from 0.16499\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1677 - loss: 3.5138 - val_accuracy: 0.1495 - val_loss: 3.5436 - learning_rate: 1.0000e-04\nEpoch 10/200\n\u001b[1m4016/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1710 - loss: 3.4746\nEpoch 10: val_accuracy did not improve from 0.16499\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1711 - loss: 3.4746 - val_accuracy: 0.1471 - val_loss: 3.5411 - learning_rate: 1.0000e-04\nEpoch 11/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1748 - loss: 3.4421\nEpoch 11: val_accuracy improved from 0.16499 to 0.18229, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1748 - loss: 3.4421 - val_accuracy: 0.1823 - val_loss: 3.4020 - learning_rate: 1.0000e-04\nEpoch 12/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1796 - loss: 3.4158\nEpoch 12: val_accuracy did not improve from 0.18229\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1796 - loss: 3.4158 - val_accuracy: 0.1806 - val_loss: 3.3896 - learning_rate: 1.0000e-04\nEpoch 13/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1832 - loss: 3.3931\nEpoch 13: val_accuracy did not improve from 0.18229\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1832 - loss: 3.3931 - val_accuracy: 0.1769 - val_loss: 3.3852 - learning_rate: 1.0000e-04\nEpoch 14/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1876 - loss: 3.3674\nEpoch 14: val_accuracy did not improve from 0.18229\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1876 - loss: 3.3674 - val_accuracy: 0.1716 - val_loss: 3.3967 - learning_rate: 1.0000e-04\nEpoch 15/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1883 - loss: 3.3577\nEpoch 15: val_accuracy did not improve from 0.18229\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1883 - loss: 3.3577 - val_accuracy: 0.1772 - val_loss: 3.3840 - learning_rate: 1.0000e-04\nEpoch 16/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1944 - loss: 3.3405\nEpoch 16: val_accuracy improved from 0.18229 to 0.19054, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.1944 - loss: 3.3405 - val_accuracy: 0.1905 - val_loss: 3.3375 - learning_rate: 1.0000e-04\nEpoch 17/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1983 - loss: 3.3264\nEpoch 17: val_accuracy did not improve from 0.19054\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1983 - loss: 3.3263 - val_accuracy: 0.1874 - val_loss: 3.3599 - learning_rate: 1.0000e-04\nEpoch 18/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2005 - loss: 3.2995\nEpoch 18: val_accuracy did not improve from 0.19054\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2005 - loss: 3.2995 - val_accuracy: 0.1757 - val_loss: 3.4171 - learning_rate: 1.0000e-04\nEpoch 19/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2019 - loss: 3.2948\nEpoch 19: val_accuracy did not improve from 0.19054\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2019 - loss: 3.2948 - val_accuracy: 0.1855 - val_loss: 3.3796 - learning_rate: 1.0000e-04\nEpoch 20/200\n\u001b[1m4016/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2068 - loss: 3.2823\nEpoch 20: val_accuracy improved from 0.19054 to 0.19760, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2068 - loss: 3.2823 - val_accuracy: 0.1976 - val_loss: 3.3208 - learning_rate: 1.0000e-04\nEpoch 21/200\n\u001b[1m4016/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2072 - loss: 3.2786\nEpoch 21: val_accuracy did not improve from 0.19760\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2072 - loss: 3.2786 - val_accuracy: 0.1950 - val_loss: 3.3085 - learning_rate: 1.0000e-04\nEpoch 22/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2096 - loss: 3.2658\nEpoch 22: val_accuracy did not improve from 0.19760\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2096 - loss: 3.2658 - val_accuracy: 0.1923 - val_loss: 3.3182 - learning_rate: 1.0000e-04\nEpoch 23/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2136 - loss: 3.2535\nEpoch 23: val_accuracy improved from 0.19760 to 0.20040, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2136 - loss: 3.2535 - val_accuracy: 0.2004 - val_loss: 3.2938 - learning_rate: 1.0000e-04\nEpoch 24/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2134 - loss: 3.2515\nEpoch 24: val_accuracy improved from 0.20040 to 0.22107, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2134 - loss: 3.2515 - val_accuracy: 0.2211 - val_loss: 3.2310 - learning_rate: 1.0000e-04\nEpoch 25/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2128 - loss: 3.2471\nEpoch 25: val_accuracy improved from 0.22107 to 0.22266, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2128 - loss: 3.2471 - val_accuracy: 0.2227 - val_loss: 3.2739 - learning_rate: 1.0000e-04\nEpoch 26/200\n\u001b[1m4008/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2184 - loss: 3.2304\nEpoch 26: val_accuracy did not improve from 0.22266\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2184 - loss: 3.2304 - val_accuracy: 0.1953 - val_loss: 3.3202 - learning_rate: 1.0000e-04\nEpoch 27/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2205 - loss: 3.2231\nEpoch 27: val_accuracy did not improve from 0.22266\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2205 - loss: 3.2231 - val_accuracy: 0.1714 - val_loss: 3.4083 - learning_rate: 1.0000e-04\nEpoch 28/200\n\u001b[1m4007/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2172 - loss: 3.2292\nEpoch 28: val_accuracy did not improve from 0.22266\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2172 - loss: 3.2292 - val_accuracy: 0.1922 - val_loss: 3.3114 - learning_rate: 1.0000e-04\nEpoch 29/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2224 - loss: 3.2164\nEpoch 29: val_accuracy did not improve from 0.22266\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2224 - loss: 3.2164 - val_accuracy: 0.1778 - val_loss: 3.4128 - learning_rate: 1.0000e-04\nEpoch 30/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2217 - loss: 3.2134\nEpoch 30: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 30: val_accuracy did not improve from 0.22266\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2217 - loss: 3.2134 - val_accuracy: 0.2105 - val_loss: 3.2885 - learning_rate: 1.0000e-04\nEpoch 31/200\n\u001b[1m4008/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2292 - loss: 3.1724\nEpoch 31: val_accuracy improved from 0.22266 to 0.29063, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2292 - loss: 3.1724 - val_accuracy: 0.2906 - val_loss: 2.9309 - learning_rate: 1.0000e-05\nEpoch 32/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2329 - loss: 3.1523\nEpoch 32: val_accuracy improved from 0.29063 to 0.29157, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2329 - loss: 3.1523 - val_accuracy: 0.2916 - val_loss: 2.9268 - learning_rate: 1.0000e-05\nEpoch 33/200\n\u001b[1m3998/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2398 - loss: 3.1391\nEpoch 33: val_accuracy improved from 0.29157 to 0.29396, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2397 - loss: 3.1391 - val_accuracy: 0.2940 - val_loss: 2.9216 - learning_rate: 1.0000e-05\nEpoch 34/200\n\u001b[1m4016/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2385 - loss: 3.1337\nEpoch 34: val_accuracy improved from 0.29396 to 0.29527, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2385 - loss: 3.1337 - val_accuracy: 0.2953 - val_loss: 2.9039 - learning_rate: 1.0000e-05\nEpoch 35/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2371 - loss: 3.1305\nEpoch 35: val_accuracy improved from 0.29527 to 0.29904, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2371 - loss: 3.1305 - val_accuracy: 0.2990 - val_loss: 2.9039 - learning_rate: 1.0000e-05\nEpoch 36/200\n\u001b[1m4002/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2376 - loss: 3.1299\nEpoch 36: val_accuracy did not improve from 0.29904\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2376 - loss: 3.1299 - val_accuracy: 0.2989 - val_loss: 2.8994 - learning_rate: 1.0000e-05\nEpoch 37/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2375 - loss: 3.1266\nEpoch 37: val_accuracy improved from 0.29904 to 0.30184, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2375 - loss: 3.1266 - val_accuracy: 0.3018 - val_loss: 2.8878 - learning_rate: 1.0000e-05\nEpoch 38/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2406 - loss: 3.1157\nEpoch 38: val_accuracy did not improve from 0.30184\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2406 - loss: 3.1157 - val_accuracy: 0.2983 - val_loss: 2.8928 - learning_rate: 1.0000e-05\nEpoch 39/200\n\u001b[1m4012/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2383 - loss: 3.1180\nEpoch 39: val_accuracy improved from 0.30184 to 0.30314, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2383 - loss: 3.1180 - val_accuracy: 0.3031 - val_loss: 2.8860 - learning_rate: 1.0000e-05\nEpoch 40/200\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2395 - loss: 3.1134\nEpoch 40: val_accuracy improved from 0.30314 to 0.30398, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2395 - loss: 3.1134 - val_accuracy: 0.3040 - val_loss: 2.8799 - learning_rate: 1.0000e-05\nEpoch 41/200\n\u001b[1m4012/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2403 - loss: 3.1150\nEpoch 41: val_accuracy did not improve from 0.30398\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2403 - loss: 3.1150 - val_accuracy: 0.3019 - val_loss: 2.8768 - learning_rate: 1.0000e-05\nEpoch 42/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2416 - loss: 3.1097\nEpoch 42: val_accuracy did not improve from 0.30398\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2416 - loss: 3.1097 - val_accuracy: 0.3031 - val_loss: 2.8699 - learning_rate: 1.0000e-05\nEpoch 43/200\n\u001b[1m4002/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2416 - loss: 3.1115\nEpoch 43: val_accuracy improved from 0.30398 to 0.30523, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2416 - loss: 3.1115 - val_accuracy: 0.3052 - val_loss: 2.8726 - learning_rate: 1.0000e-05\nEpoch 44/200\n\u001b[1m4001/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2409 - loss: 3.1067\nEpoch 44: val_accuracy did not improve from 0.30523\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2409 - loss: 3.1067 - val_accuracy: 0.3023 - val_loss: 2.8728 - learning_rate: 1.0000e-05\nEpoch 45/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2415 - loss: 3.1058\nEpoch 45: val_accuracy did not improve from 0.30523\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2415 - loss: 3.1058 - val_accuracy: 0.3018 - val_loss: 2.8762 - learning_rate: 1.0000e-05\nEpoch 46/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2445 - loss: 3.0977\nEpoch 46: val_accuracy did not improve from 0.30523\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2445 - loss: 3.0977 - val_accuracy: 0.2983 - val_loss: 2.8766 - learning_rate: 1.0000e-05\nEpoch 47/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2398 - loss: 3.1085\nEpoch 47: val_accuracy did not improve from 0.30523\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2398 - loss: 3.1085 - val_accuracy: 0.2980 - val_loss: 2.8759 - learning_rate: 1.0000e-05\nEpoch 48/200\n\u001b[1m4011/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2426 - loss: 3.0946\nEpoch 48: ReduceLROnPlateau reducing learning rate to 1e-06.\n\nEpoch 48: val_accuracy did not improve from 0.30523\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2426 - loss: 3.0946 - val_accuracy: 0.3048 - val_loss: 2.8574 - learning_rate: 1.0000e-05\nEpoch 49/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2441 - loss: 3.0900\nEpoch 49: val_accuracy improved from 0.30523 to 0.30856, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2441 - loss: 3.0900 - val_accuracy: 0.3086 - val_loss: 2.8437 - learning_rate: 1.0000e-06\nEpoch 50/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2426 - loss: 3.0924\nEpoch 50: val_accuracy improved from 0.30856 to 0.30934, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2426 - loss: 3.0924 - val_accuracy: 0.3093 - val_loss: 2.8412 - learning_rate: 1.0000e-06\nEpoch 51/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 3.0813\nEpoch 51: val_accuracy improved from 0.30934 to 0.30999, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 3.0813 - val_accuracy: 0.3100 - val_loss: 2.8422 - learning_rate: 1.0000e-06\nEpoch 52/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2440 - loss: 3.0879\nEpoch 52: val_accuracy did not improve from 0.30999\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2440 - loss: 3.0879 - val_accuracy: 0.3094 - val_loss: 2.8407 - learning_rate: 1.0000e-06\nEpoch 53/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2454 - loss: 3.0849\nEpoch 53: val_accuracy did not improve from 0.30999\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2454 - loss: 3.0849 - val_accuracy: 0.3089 - val_loss: 2.8389 - learning_rate: 1.0000e-06\nEpoch 54/200\n\u001b[1m4001/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2413 - loss: 3.0907\nEpoch 54: val_accuracy did not improve from 0.30999\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2413 - loss: 3.0907 - val_accuracy: 0.3096 - val_loss: 2.8384 - learning_rate: 1.0000e-06\nEpoch 55/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2439 - loss: 3.0884\nEpoch 55: val_accuracy did not improve from 0.30999\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2439 - loss: 3.0884 - val_accuracy: 0.3096 - val_loss: 2.8374 - learning_rate: 1.0000e-06\nEpoch 56/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2432 - loss: 3.0870\nEpoch 56: val_accuracy improved from 0.30999 to 0.31083, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2432 - loss: 3.0870 - val_accuracy: 0.3108 - val_loss: 2.8394 - learning_rate: 1.0000e-06\nEpoch 57/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2445 - loss: 3.0882\nEpoch 57: val_accuracy did not improve from 0.31083\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2445 - loss: 3.0882 - val_accuracy: 0.3096 - val_loss: 2.8366 - learning_rate: 1.0000e-06\nEpoch 58/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2461 - loss: 3.0837\nEpoch 58: val_accuracy improved from 0.31083 to 0.31092, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2461 - loss: 3.0837 - val_accuracy: 0.3109 - val_loss: 2.8375 - learning_rate: 1.0000e-06\nEpoch 59/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 3.0899\nEpoch 59: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 3.0899 - val_accuracy: 0.3099 - val_loss: 2.8367 - learning_rate: 1.0000e-06\nEpoch 60/200\n\u001b[1m4007/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2439 - loss: 3.0917\nEpoch 60: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2439 - loss: 3.0917 - val_accuracy: 0.3091 - val_loss: 2.8348 - learning_rate: 1.0000e-06\nEpoch 61/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2450 - loss: 3.0869\nEpoch 61: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2450 - loss: 3.0869 - val_accuracy: 0.3092 - val_loss: 2.8366 - learning_rate: 1.0000e-06\nEpoch 62/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2488 - loss: 3.0758\nEpoch 62: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2488 - loss: 3.0759 - val_accuracy: 0.3101 - val_loss: 2.8350 - learning_rate: 1.0000e-06\nEpoch 63/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2436 - loss: 3.0899\nEpoch 63: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2436 - loss: 3.0899 - val_accuracy: 0.3090 - val_loss: 2.8319 - learning_rate: 1.0000e-06\nEpoch 64/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 3.0810\nEpoch 64: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 3.0810 - val_accuracy: 0.3101 - val_loss: 2.8338 - learning_rate: 1.0000e-06\nEpoch 65/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 3.0850\nEpoch 65: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 3.0850 - val_accuracy: 0.3108 - val_loss: 2.8328 - learning_rate: 1.0000e-06\nEpoch 66/200\n\u001b[1m4011/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2453 - loss: 3.0835\nEpoch 66: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2453 - loss: 3.0835 - val_accuracy: 0.3109 - val_loss: 2.8352 - learning_rate: 1.0000e-06\nEpoch 67/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2430 - loss: 3.0905\nEpoch 67: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2430 - loss: 3.0905 - val_accuracy: 0.3099 - val_loss: 2.8308 - learning_rate: 1.0000e-06\nEpoch 68/200\n\u001b[1m4001/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 3.0763\nEpoch 68: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 3.0763 - val_accuracy: 0.3109 - val_loss: 2.8325 - learning_rate: 1.0000e-06\nEpoch 69/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2436 - loss: 3.0856\nEpoch 69: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2436 - loss: 3.0856 - val_accuracy: 0.3105 - val_loss: 2.8308 - learning_rate: 1.0000e-06\nEpoch 70/200\n\u001b[1m4008/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 3.0774\nEpoch 70: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 3.0774 - val_accuracy: 0.3104 - val_loss: 2.8311 - learning_rate: 1.0000e-06\nEpoch 71/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2445 - loss: 3.0888\nEpoch 71: val_accuracy did not improve from 0.31092\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2445 - loss: 3.0888 - val_accuracy: 0.3109 - val_loss: 2.8312 - learning_rate: 1.0000e-06\nEpoch 72/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2435 - loss: 3.0822\nEpoch 72: val_accuracy improved from 0.31092 to 0.31136, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.2435 - loss: 3.0822 - val_accuracy: 0.3114 - val_loss: 2.8308 - learning_rate: 1.0000e-06\nEpoch 73/200\n\u001b[1m3998/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2426 - loss: 3.0860\nEpoch 73: val_accuracy did not improve from 0.31136\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2426 - loss: 3.0860 - val_accuracy: 0.3108 - val_loss: 2.8323 - learning_rate: 1.0000e-06\nEpoch 74/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2440 - loss: 3.0835\nEpoch 74: val_accuracy did not improve from 0.31136\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2440 - loss: 3.0835 - val_accuracy: 0.3110 - val_loss: 2.8303 - learning_rate: 1.0000e-06\nEpoch 75/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2450 - loss: 3.0795\nEpoch 75: val_accuracy did not improve from 0.31136\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2450 - loss: 3.0795 - val_accuracy: 0.3108 - val_loss: 2.8299 - learning_rate: 1.0000e-06\nEpoch 76/200\n\u001b[1m4012/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2449 - loss: 3.0837\nEpoch 76: val_accuracy did not improve from 0.31136\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2449 - loss: 3.0837 - val_accuracy: 0.3102 - val_loss: 2.8314 - learning_rate: 1.0000e-06\nEpoch 77/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2471 - loss: 3.0807\nEpoch 77: val_accuracy improved from 0.31136 to 0.31201, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2471 - loss: 3.0807 - val_accuracy: 0.3120 - val_loss: 2.8297 - learning_rate: 1.0000e-06\nEpoch 78/200\n\u001b[1m3998/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2434 - loss: 3.0890\nEpoch 78: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2434 - loss: 3.0890 - val_accuracy: 0.3117 - val_loss: 2.8283 - learning_rate: 1.0000e-06\nEpoch 79/200\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2444 - loss: 3.0834\nEpoch 79: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2444 - loss: 3.0834 - val_accuracy: 0.3105 - val_loss: 2.8290 - learning_rate: 1.0000e-06\nEpoch 80/200\n\u001b[1m3998/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2460 - loss: 3.0797\nEpoch 80: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 3.0797 - val_accuracy: 0.3111 - val_loss: 2.8266 - learning_rate: 1.0000e-06\nEpoch 81/200\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 3.0788\nEpoch 81: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 3.0788 - val_accuracy: 0.3115 - val_loss: 2.8287 - learning_rate: 1.0000e-06\nEpoch 82/200\n\u001b[1m4016/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2453 - loss: 3.0782\nEpoch 82: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2453 - loss: 3.0782 - val_accuracy: 0.3106 - val_loss: 2.8297 - learning_rate: 1.0000e-06\nEpoch 83/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2456 - loss: 3.0768\nEpoch 83: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2456 - loss: 3.0769 - val_accuracy: 0.3120 - val_loss: 2.8265 - learning_rate: 1.0000e-06\nEpoch 84/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2486 - loss: 3.0746\nEpoch 84: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2486 - loss: 3.0746 - val_accuracy: 0.3113 - val_loss: 2.8253 - learning_rate: 1.0000e-06\nEpoch 85/200\n\u001b[1m4011/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2455 - loss: 3.0835\nEpoch 85: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2455 - loss: 3.0835 - val_accuracy: 0.3117 - val_loss: 2.8256 - learning_rate: 1.0000e-06\nEpoch 86/200\n\u001b[1m4001/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2434 - loss: 3.0838\nEpoch 86: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2434 - loss: 3.0838 - val_accuracy: 0.3115 - val_loss: 2.8262 - learning_rate: 1.0000e-06\nEpoch 87/200\n\u001b[1m4007/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2446 - loss: 3.0809\nEpoch 87: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2446 - loss: 3.0809 - val_accuracy: 0.3110 - val_loss: 2.8244 - learning_rate: 1.0000e-06\nEpoch 88/200\n\u001b[1m3997/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2464 - loss: 3.0783\nEpoch 88: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2464 - loss: 3.0783 - val_accuracy: 0.3118 - val_loss: 2.8252 - learning_rate: 1.0000e-06\nEpoch 89/200\n\u001b[1m3998/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2432 - loss: 3.0861\nEpoch 89: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2432 - loss: 3.0861 - val_accuracy: 0.3115 - val_loss: 2.8253 - learning_rate: 1.0000e-06\nEpoch 90/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2464 - loss: 3.0808\nEpoch 90: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2464 - loss: 3.0808 - val_accuracy: 0.3119 - val_loss: 2.8257 - learning_rate: 1.0000e-06\nEpoch 91/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2455 - loss: 3.0836\nEpoch 91: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2455 - loss: 3.0836 - val_accuracy: 0.3115 - val_loss: 2.8260 - learning_rate: 1.0000e-06\nEpoch 92/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2448 - loss: 3.0828\nEpoch 92: val_accuracy did not improve from 0.31201\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2448 - loss: 3.0828 - val_accuracy: 0.3117 - val_loss: 2.8254 - learning_rate: 1.0000e-06\nEpoch 93/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2475 - loss: 3.0801\nEpoch 93: val_accuracy improved from 0.31201 to 0.31223, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2475 - loss: 3.0801 - val_accuracy: 0.3122 - val_loss: 2.8258 - learning_rate: 1.0000e-06\nEpoch 94/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2444 - loss: 3.0821\nEpoch 94: val_accuracy did not improve from 0.31223\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2444 - loss: 3.0821 - val_accuracy: 0.3114 - val_loss: 2.8248 - learning_rate: 1.0000e-06\nEpoch 95/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2486 - loss: 3.0764\nEpoch 95: val_accuracy did not improve from 0.31223\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2486 - loss: 3.0764 - val_accuracy: 0.3102 - val_loss: 2.8233 - learning_rate: 1.0000e-06\nEpoch 96/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2429 - loss: 3.0841\nEpoch 96: val_accuracy did not improve from 0.31223\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2429 - loss: 3.0841 - val_accuracy: 0.3118 - val_loss: 2.8244 - learning_rate: 1.0000e-06\nEpoch 97/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2443 - loss: 3.0835\nEpoch 97: val_accuracy did not improve from 0.31223\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2443 - loss: 3.0835 - val_accuracy: 0.3121 - val_loss: 2.8254 - learning_rate: 1.0000e-06\nEpoch 98/200\n\u001b[1m4001/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2459 - loss: 3.0811\nEpoch 98: val_accuracy did not improve from 0.31223\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2459 - loss: 3.0811 - val_accuracy: 0.3121 - val_loss: 2.8201 - learning_rate: 1.0000e-06\nEpoch 99/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2440 - loss: 3.0815\nEpoch 99: val_accuracy improved from 0.31223 to 0.31248, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2440 - loss: 3.0815 - val_accuracy: 0.3125 - val_loss: 2.8235 - learning_rate: 1.0000e-06\nEpoch 100/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2482 - loss: 3.0709\nEpoch 100: val_accuracy did not improve from 0.31248\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2482 - loss: 3.0709 - val_accuracy: 0.3116 - val_loss: 2.8219 - learning_rate: 1.0000e-06\nEpoch 101/200\n\u001b[1m4012/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2477 - loss: 3.0728\nEpoch 101: val_accuracy improved from 0.31248 to 0.31254, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2477 - loss: 3.0729 - val_accuracy: 0.3125 - val_loss: 2.8227 - learning_rate: 1.0000e-06\nEpoch 102/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2458 - loss: 3.0807\nEpoch 102: val_accuracy improved from 0.31254 to 0.31261, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2458 - loss: 3.0807 - val_accuracy: 0.3126 - val_loss: 2.8225 - learning_rate: 1.0000e-06\nEpoch 103/200\n\u001b[1m4007/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2454 - loss: 3.0752\nEpoch 103: val_accuracy did not improve from 0.31261\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2454 - loss: 3.0752 - val_accuracy: 0.3120 - val_loss: 2.8255 - learning_rate: 1.0000e-06\nEpoch 104/200\n\u001b[1m4001/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2477 - loss: 3.0766\nEpoch 104: val_accuracy did not improve from 0.31261\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2477 - loss: 3.0766 - val_accuracy: 0.3122 - val_loss: 2.8217 - learning_rate: 1.0000e-06\nEpoch 105/200\n\u001b[1m4007/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2469 - loss: 3.0718\nEpoch 105: val_accuracy did not improve from 0.31261\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2469 - loss: 3.0718 - val_accuracy: 0.3116 - val_loss: 2.8219 - learning_rate: 1.0000e-06\nEpoch 106/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2484 - loss: 3.0703\nEpoch 106: val_accuracy did not improve from 0.31261\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2484 - loss: 3.0703 - val_accuracy: 0.3126 - val_loss: 2.8206 - learning_rate: 1.0000e-06\nEpoch 107/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2457 - loss: 3.0749\nEpoch 107: val_accuracy improved from 0.31261 to 0.31285, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 3.0749 - val_accuracy: 0.3129 - val_loss: 2.8199 - learning_rate: 1.0000e-06\nEpoch 108/200\n\u001b[1m4011/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 3.0767\nEpoch 108: val_accuracy did not improve from 0.31285\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 3.0767 - val_accuracy: 0.3127 - val_loss: 2.8220 - learning_rate: 1.0000e-06\nEpoch 109/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2478 - loss: 3.0754\nEpoch 109: val_accuracy improved from 0.31285 to 0.31301, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2478 - loss: 3.0754 - val_accuracy: 0.3130 - val_loss: 2.8224 - learning_rate: 1.0000e-06\nEpoch 110/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2430 - loss: 3.0805\nEpoch 110: val_accuracy did not improve from 0.31301\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2430 - loss: 3.0805 - val_accuracy: 0.3129 - val_loss: 2.8195 - learning_rate: 1.0000e-06\nEpoch 111/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2453 - loss: 3.0756\nEpoch 111: val_accuracy did not improve from 0.31301\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2453 - loss: 3.0756 - val_accuracy: 0.3125 - val_loss: 2.8198 - learning_rate: 1.0000e-06\nEpoch 112/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2431 - loss: 3.0748\nEpoch 112: val_accuracy improved from 0.31301 to 0.31332, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2431 - loss: 3.0748 - val_accuracy: 0.3133 - val_loss: 2.8222 - learning_rate: 1.0000e-06\nEpoch 113/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2469 - loss: 3.0719\nEpoch 113: val_accuracy did not improve from 0.31332\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2468 - loss: 3.0719 - val_accuracy: 0.3129 - val_loss: 2.8190 - learning_rate: 1.0000e-06\nEpoch 114/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2452 - loss: 3.0790\nEpoch 114: val_accuracy did not improve from 0.31332\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2452 - loss: 3.0790 - val_accuracy: 0.3131 - val_loss: 2.8181 - learning_rate: 1.0000e-06\nEpoch 115/200\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2490 - loss: 3.0690\nEpoch 115: val_accuracy did not improve from 0.31332\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2490 - loss: 3.0690 - val_accuracy: 0.3131 - val_loss: 2.8178 - learning_rate: 1.0000e-06\nEpoch 116/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2449 - loss: 3.0782\nEpoch 116: val_accuracy did not improve from 0.31332\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2449 - loss: 3.0782 - val_accuracy: 0.3130 - val_loss: 2.8172 - learning_rate: 1.0000e-06\nEpoch 117/200\n\u001b[1m4001/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2468 - loss: 3.0711\nEpoch 117: val_accuracy did not improve from 0.31332\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2468 - loss: 3.0711 - val_accuracy: 0.3132 - val_loss: 2.8181 - learning_rate: 1.0000e-06\nEpoch 118/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2448 - loss: 3.0781\nEpoch 118: val_accuracy did not improve from 0.31332\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2448 - loss: 3.0781 - val_accuracy: 0.3127 - val_loss: 2.8211 - learning_rate: 1.0000e-06\nEpoch 119/200\n\u001b[1m4012/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2472 - loss: 3.0707\nEpoch 119: val_accuracy improved from 0.31332 to 0.31345, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2472 - loss: 3.0707 - val_accuracy: 0.3134 - val_loss: 2.8195 - learning_rate: 1.0000e-06\nEpoch 120/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2461 - loss: 3.0804\nEpoch 120: val_accuracy did not improve from 0.31345\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2461 - loss: 3.0803 - val_accuracy: 0.3132 - val_loss: 2.8163 - learning_rate: 1.0000e-06\nEpoch 121/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2451 - loss: 3.0722\nEpoch 121: val_accuracy improved from 0.31345 to 0.31354, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2451 - loss: 3.0722 - val_accuracy: 0.3135 - val_loss: 2.8178 - learning_rate: 1.0000e-06\nEpoch 122/200\n\u001b[1m4011/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2468 - loss: 3.0721\nEpoch 122: val_accuracy did not improve from 0.31354\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2468 - loss: 3.0721 - val_accuracy: 0.3132 - val_loss: 2.8169 - learning_rate: 1.0000e-06\nEpoch 123/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2461 - loss: 3.0719\nEpoch 123: val_accuracy did not improve from 0.31354\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2461 - loss: 3.0719 - val_accuracy: 0.3128 - val_loss: 2.8163 - learning_rate: 1.0000e-06\nEpoch 124/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2465 - loss: 3.0679\nEpoch 124: val_accuracy did not improve from 0.31354\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2465 - loss: 3.0680 - val_accuracy: 0.3124 - val_loss: 2.8158 - learning_rate: 1.0000e-06\nEpoch 125/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2441 - loss: 3.0792\nEpoch 125: val_accuracy did not improve from 0.31354\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2441 - loss: 3.0791 - val_accuracy: 0.3121 - val_loss: 2.8182 - learning_rate: 1.0000e-06\nEpoch 126/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2458 - loss: 3.0758\nEpoch 126: val_accuracy did not improve from 0.31354\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2458 - loss: 3.0758 - val_accuracy: 0.3130 - val_loss: 2.8131 - learning_rate: 1.0000e-06\nEpoch 127/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2476 - loss: 3.0683\nEpoch 127: val_accuracy did not improve from 0.31354\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.2476 - loss: 3.0683 - val_accuracy: 0.3127 - val_loss: 2.8159 - learning_rate: 1.0000e-06\nEpoch 128/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2456 - loss: 3.0755\nEpoch 128: val_accuracy improved from 0.31354 to 0.31363, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2456 - loss: 3.0755 - val_accuracy: 0.3136 - val_loss: 2.8165 - learning_rate: 1.0000e-06\nEpoch 129/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2443 - loss: 3.0771\nEpoch 129: val_accuracy did not improve from 0.31363\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2443 - loss: 3.0771 - val_accuracy: 0.3128 - val_loss: 2.8147 - learning_rate: 1.0000e-06\nEpoch 130/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2487 - loss: 3.0684\nEpoch 130: val_accuracy did not improve from 0.31363\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2487 - loss: 3.0684 - val_accuracy: 0.3128 - val_loss: 2.8153 - learning_rate: 1.0000e-06\nEpoch 131/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2477 - loss: 3.0691\nEpoch 131: val_accuracy improved from 0.31363 to 0.31369, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2477 - loss: 3.0691 - val_accuracy: 0.3137 - val_loss: 2.8118 - learning_rate: 1.0000e-06\nEpoch 132/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2458 - loss: 3.0680\nEpoch 132: val_accuracy improved from 0.31369 to 0.31429, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2458 - loss: 3.0680 - val_accuracy: 0.3143 - val_loss: 2.8121 - learning_rate: 1.0000e-06\nEpoch 133/200\n\u001b[1m3998/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2453 - loss: 3.0699\nEpoch 133: val_accuracy did not improve from 0.31429\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2453 - loss: 3.0699 - val_accuracy: 0.3141 - val_loss: 2.8106 - learning_rate: 1.0000e-06\nEpoch 134/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2452 - loss: 3.0759\nEpoch 134: val_accuracy did not improve from 0.31429\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2452 - loss: 3.0759 - val_accuracy: 0.3130 - val_loss: 2.8117 - learning_rate: 1.0000e-06\nEpoch 135/200\n\u001b[1m3997/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2456 - loss: 3.0710\nEpoch 135: val_accuracy did not improve from 0.31429\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2456 - loss: 3.0710 - val_accuracy: 0.3141 - val_loss: 2.8125 - learning_rate: 1.0000e-06\nEpoch 136/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2452 - loss: 3.0727\nEpoch 136: val_accuracy did not improve from 0.31429\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2452 - loss: 3.0726 - val_accuracy: 0.3142 - val_loss: 2.8123 - learning_rate: 1.0000e-06\nEpoch 137/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2472 - loss: 3.0663\nEpoch 137: val_accuracy did not improve from 0.31429\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2472 - loss: 3.0664 - val_accuracy: 0.3134 - val_loss: 2.8114 - learning_rate: 1.0000e-06\nEpoch 138/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2477 - loss: 3.0692\nEpoch 138: val_accuracy did not improve from 0.31429\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2477 - loss: 3.0692 - val_accuracy: 0.3137 - val_loss: 2.8124 - learning_rate: 1.0000e-06\nEpoch 139/200\n\u001b[1m4008/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2464 - loss: 3.0733\nEpoch 139: val_accuracy did not improve from 0.31429\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2464 - loss: 3.0733 - val_accuracy: 0.3138 - val_loss: 2.8108 - learning_rate: 1.0000e-06\nEpoch 140/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2468 - loss: 3.0724\nEpoch 140: val_accuracy improved from 0.31429 to 0.31457, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2468 - loss: 3.0724 - val_accuracy: 0.3146 - val_loss: 2.8120 - learning_rate: 1.0000e-06\nEpoch 141/200\n\u001b[1m3998/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2464 - loss: 3.0730\nEpoch 141: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2464 - loss: 3.0730 - val_accuracy: 0.3139 - val_loss: 2.8146 - learning_rate: 1.0000e-06\nEpoch 142/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2466 - loss: 3.0673\nEpoch 142: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2466 - loss: 3.0673 - val_accuracy: 0.3132 - val_loss: 2.8130 - learning_rate: 1.0000e-06\nEpoch 143/200\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2472 - loss: 3.0699\nEpoch 143: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2472 - loss: 3.0699 - val_accuracy: 0.3142 - val_loss: 2.8082 - learning_rate: 1.0000e-06\nEpoch 144/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2449 - loss: 3.0735\nEpoch 144: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2449 - loss: 3.0735 - val_accuracy: 0.3134 - val_loss: 2.8099 - learning_rate: 1.0000e-06\nEpoch 145/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2471 - loss: 3.0693\nEpoch 145: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2471 - loss: 3.0693 - val_accuracy: 0.3141 - val_loss: 2.8106 - learning_rate: 1.0000e-06\nEpoch 146/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2467 - loss: 3.0660\nEpoch 146: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2467 - loss: 3.0660 - val_accuracy: 0.3141 - val_loss: 2.8109 - learning_rate: 1.0000e-06\nEpoch 147/200\n\u001b[1m4008/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2468 - loss: 3.0693\nEpoch 147: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2468 - loss: 3.0693 - val_accuracy: 0.3144 - val_loss: 2.8081 - learning_rate: 1.0000e-06\nEpoch 148/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2473 - loss: 3.0693\nEpoch 148: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2473 - loss: 3.0693 - val_accuracy: 0.3142 - val_loss: 2.8085 - learning_rate: 1.0000e-06\nEpoch 149/200\n\u001b[1m4004/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2474 - loss: 3.0669\nEpoch 149: val_accuracy did not improve from 0.31457\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2474 - loss: 3.0669 - val_accuracy: 0.3138 - val_loss: 2.8084 - learning_rate: 1.0000e-06\nEpoch 150/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2471 - loss: 3.0639\nEpoch 150: val_accuracy improved from 0.31457 to 0.31513, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2471 - loss: 3.0639 - val_accuracy: 0.3151 - val_loss: 2.8093 - learning_rate: 1.0000e-06\nEpoch 151/200\n\u001b[1m4002/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2456 - loss: 3.0688\nEpoch 151: val_accuracy improved from 0.31513 to 0.31606, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2456 - loss: 3.0688 - val_accuracy: 0.3161 - val_loss: 2.8065 - learning_rate: 1.0000e-06\nEpoch 152/200\n\u001b[1m4002/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2472 - loss: 3.0654\nEpoch 152: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2472 - loss: 3.0654 - val_accuracy: 0.3149 - val_loss: 2.8075 - learning_rate: 1.0000e-06\nEpoch 153/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2474 - loss: 3.0671\nEpoch 153: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2474 - loss: 3.0671 - val_accuracy: 0.3148 - val_loss: 2.8075 - learning_rate: 1.0000e-06\nEpoch 154/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2480 - loss: 3.0638\nEpoch 154: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2479 - loss: 3.0638 - val_accuracy: 0.3143 - val_loss: 2.8066 - learning_rate: 1.0000e-06\nEpoch 155/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2457 - loss: 3.0679\nEpoch 155: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 3.0679 - val_accuracy: 0.3144 - val_loss: 2.8075 - learning_rate: 1.0000e-06\nEpoch 156/200\n\u001b[1m4009/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2466 - loss: 3.0700\nEpoch 156: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2466 - loss: 3.0700 - val_accuracy: 0.3156 - val_loss: 2.8078 - learning_rate: 1.0000e-06\nEpoch 157/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2464 - loss: 3.0636\nEpoch 157: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2464 - loss: 3.0636 - val_accuracy: 0.3153 - val_loss: 2.8081 - learning_rate: 1.0000e-06\nEpoch 158/200\n\u001b[1m4016/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2502 - loss: 3.0608\nEpoch 158: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2502 - loss: 3.0608 - val_accuracy: 0.3147 - val_loss: 2.8081 - learning_rate: 1.0000e-06\nEpoch 159/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2470 - loss: 3.0701\nEpoch 159: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2470 - loss: 3.0700 - val_accuracy: 0.3151 - val_loss: 2.8066 - learning_rate: 1.0000e-06\nEpoch 160/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2480 - loss: 3.0622\nEpoch 160: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2480 - loss: 3.0622 - val_accuracy: 0.3145 - val_loss: 2.8061 - learning_rate: 1.0000e-06\nEpoch 161/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2482 - loss: 3.0652\nEpoch 161: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2482 - loss: 3.0652 - val_accuracy: 0.3148 - val_loss: 2.8084 - learning_rate: 1.0000e-06\nEpoch 162/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2489 - loss: 3.0573\nEpoch 162: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2489 - loss: 3.0573 - val_accuracy: 0.3140 - val_loss: 2.8051 - learning_rate: 1.0000e-06\nEpoch 163/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2490 - loss: 3.0608\nEpoch 163: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2490 - loss: 3.0608 - val_accuracy: 0.3148 - val_loss: 2.8090 - learning_rate: 1.0000e-06\nEpoch 164/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2444 - loss: 3.0774\nEpoch 164: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2444 - loss: 3.0774 - val_accuracy: 0.3143 - val_loss: 2.8072 - learning_rate: 1.0000e-06\nEpoch 165/200\n\u001b[1m3997/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2471 - loss: 3.0674\nEpoch 165: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2471 - loss: 3.0674 - val_accuracy: 0.3153 - val_loss: 2.8049 - learning_rate: 1.0000e-06\nEpoch 166/200\n\u001b[1m4015/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2475 - loss: 3.0568\nEpoch 166: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2475 - loss: 3.0568 - val_accuracy: 0.3152 - val_loss: 2.8056 - learning_rate: 1.0000e-06\nEpoch 167/200\n\u001b[1m4002/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2470 - loss: 3.0674\nEpoch 167: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2470 - loss: 3.0674 - val_accuracy: 0.3142 - val_loss: 2.8037 - learning_rate: 1.0000e-06\nEpoch 168/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2480 - loss: 3.0649\nEpoch 168: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.2480 - loss: 3.0649 - val_accuracy: 0.3144 - val_loss: 2.8025 - learning_rate: 1.0000e-06\nEpoch 169/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2493 - loss: 3.0633\nEpoch 169: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2493 - loss: 3.0633 - val_accuracy: 0.3154 - val_loss: 2.8057 - learning_rate: 1.0000e-06\nEpoch 170/200\n\u001b[1m4007/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2472 - loss: 3.0696\nEpoch 170: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2472 - loss: 3.0696 - val_accuracy: 0.3157 - val_loss: 2.8010 - learning_rate: 1.0000e-06\nEpoch 171/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2482 - loss: 3.0567\nEpoch 171: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2482 - loss: 3.0568 - val_accuracy: 0.3151 - val_loss: 2.8048 - learning_rate: 1.0000e-06\nEpoch 172/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2472 - loss: 3.0658\nEpoch 172: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2472 - loss: 3.0658 - val_accuracy: 0.3150 - val_loss: 2.8029 - learning_rate: 1.0000e-06\nEpoch 173/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2481 - loss: 3.0636\nEpoch 173: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2481 - loss: 3.0636 - val_accuracy: 0.3155 - val_loss: 2.8060 - learning_rate: 1.0000e-06\nEpoch 174/200\n\u001b[1m4010/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2464 - loss: 3.0655\nEpoch 174: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2464 - loss: 3.0655 - val_accuracy: 0.3147 - val_loss: 2.8004 - learning_rate: 1.0000e-06\nEpoch 175/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2452 - loss: 3.0690\nEpoch 175: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2452 - loss: 3.0690 - val_accuracy: 0.3157 - val_loss: 2.8027 - learning_rate: 1.0000e-06\nEpoch 176/200\n\u001b[1m4007/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2484 - loss: 3.0652\nEpoch 176: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2484 - loss: 3.0652 - val_accuracy: 0.3152 - val_loss: 2.8051 - learning_rate: 1.0000e-06\nEpoch 177/200\n\u001b[1m4012/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2467 - loss: 3.0646\nEpoch 177: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2467 - loss: 3.0646 - val_accuracy: 0.3154 - val_loss: 2.7996 - learning_rate: 1.0000e-06\nEpoch 178/200\n\u001b[1m4006/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2477 - loss: 3.0638\nEpoch 178: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2477 - loss: 3.0638 - val_accuracy: 0.3156 - val_loss: 2.8043 - learning_rate: 1.0000e-06\nEpoch 179/200\n\u001b[1m4003/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2490 - loss: 3.0587\nEpoch 179: val_accuracy did not improve from 0.31606\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2490 - loss: 3.0587 - val_accuracy: 0.3158 - val_loss: 2.8039 - learning_rate: 1.0000e-06\nEpoch 180/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2497 - loss: 3.0582\nEpoch 180: val_accuracy improved from 0.31606 to 0.31634, saving model to best_model.keras\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2497 - loss: 3.0582 - val_accuracy: 0.3163 - val_loss: 2.8022 - learning_rate: 1.0000e-06\nEpoch 181/200\n\u001b[1m4014/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2479 - loss: 3.0685\nEpoch 181: val_accuracy did not improve from 0.31634\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2479 - loss: 3.0685 - val_accuracy: 0.3153 - val_loss: 2.8012 - learning_rate: 1.0000e-06\nEpoch 182/200\n\u001b[1m4013/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2486 - loss: 3.0675\nEpoch 182: val_accuracy did not improve from 0.31634\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2486 - loss: 3.0675 - val_accuracy: 0.3153 - val_loss: 2.8030 - learning_rate: 1.0000e-06\nEpoch 183/200\n\u001b[1m3999/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2493 - loss: 3.0647\nEpoch 183: val_accuracy did not improve from 0.31634\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2493 - loss: 3.0647 - val_accuracy: 0.3158 - val_loss: 2.8021 - learning_rate: 1.0000e-06\nEpoch 184/200\n\u001b[1m4000/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2484 - loss: 3.0587\nEpoch 184: val_accuracy did not improve from 0.31634\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2484 - loss: 3.0587 - val_accuracy: 0.3162 - val_loss: 2.8002 - learning_rate: 1.0000e-06\nEpoch 185/200\n\u001b[1m4002/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2482 - loss: 3.0616\nEpoch 185: val_accuracy did not improve from 0.31634\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2482 - loss: 3.0616 - val_accuracy: 0.3161 - val_loss: 2.8018 - learning_rate: 1.0000e-06\nEpoch 186/200\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2482 - loss: 3.0631\nEpoch 186: val_accuracy did not improve from 0.31634\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2482 - loss: 3.0631 - val_accuracy: 0.3153 - val_loss: 2.8018 - learning_rate: 1.0000e-06\nEpoch 187/200\n\u001b[1m4005/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2458 - loss: 3.0705\nEpoch 187: val_accuracy did not improve from 0.31634\n\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2458 - loss: 3.0705 - val_accuracy: 0.3157 - val_loss: 2.7997 - learning_rate: 1.0000e-06\nEpoch 187: early stopping\nRestoring model weights from the end of the best epoch: 177.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test accuracy: {test_accuracy:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:55:24.565340Z","iopub.execute_input":"2024-07-03T15:55:24.565636Z","iopub.status.idle":"2024-07-03T15:55:26.139266Z","shell.execute_reply.started":"2024-07-03T15:55:24.565609Z","shell.execute_reply":"2024-07-03T15:55:26.138223Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Test accuracy: 0.31541\n","output_type":"stream"}]},{"cell_type":"code","source":"# Learning Curve\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], marker='o')\nplt.plot(history.history['val_accuracy'], marker='o')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T15:55:26.140502Z","iopub.execute_input":"2024-07-03T15:55:26.140906Z","iopub.status.idle":"2024-07-03T15:55:26.390453Z","shell.execute_reply.started":"2024-07-03T15:55:26.140871Z","shell.execute_reply":"2024-07-03T15:55:26.389408Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}